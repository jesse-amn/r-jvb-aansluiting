---
title: "Aansluiting Item Analyse"
author: "J.F.J. (Jesse) van Bussel"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  html_document:
    theme: readable
    toc: true # table of contents
    toc_float: true # float: stays up left
    css: ["./css/custom.css", "./css/style_documentation.css"]
---
```{r Environment set-up, echo=FALSE, message=FALSE, warning=FALSE}
# Load files
library(here)
library(tools)
factor_analyses <- read.csv(here("data/factor_analyses_simple2023/recommended_factors.csv"))

names <- list.files(here("data/factor_analyses_simple2023/"), full.names = TRUE)
names <- names[grepl(".Rdata", names)]


# Load files
for (file in names) {
  load(file, envir = .GlobalEnv)
  # Rename an object in the global environment
  assign(file_path_sans_ext(basename(file)), item_analyses, envir = .GlobalEnv)
  rm(file)
}
rm(names)
```


# Aansluiting Item Analyse

## Introductie

Binnen dit document worden de resultaten van de item analyse voorgelegd. De resultaten zijn voornamelijk gebaseerd op factor-analytische procedures.
Specifiek zijn alle onderdelen van de aansluiting onderworpen aan een confirmatieve factor analyse (CFA). De resultaten van deze analyses zijn te vinden in de map `data/factor_analyses_simple2023/`. 
De resultaten van de CFA's zijn vervolgens gebruikt om de vragen van de onderdelen van de aansluiting te beoordelen op hun kwaliteit, waar kwaliteit beoordeelt wordt door
een combinatie van factor loadings, itemcorrelaties, en model fit indices. 

Om een beter beeld te krijgen of de hoeveelheid factoren van de onderliggende elementen daadwerkelijk eenduidig genoeg zijn, zijn er exploratieve methodes gebruikt om dit te verder te onderzoeken. Hierbij
zijn een Scree plot, met factor analyse en principiele componenten analyse vergelijk, alsook een parallel analyse gebruikt. De resultaten van deze analyses zijn te vinden in de map `data/factor_analyses_simple2023/fa_graphs`.
De resultaten van deze grafische methoden zijn gebruikt om de resultaten van de CFA's te ondersteunen, of te ontkrachten. Bij enkele onderdelen is er een alternatieve factor analyse uitgevoerd.
Dit is gedaan voor de onderdelen waarbij de resultaten van de CFA's niet eenduidig waren, en de grafische methoden een hoger nummer aan factoren aangaven. De nieuwe CFA's 
zijn uitgevoerd met het laagst aantal factoren dat de grafische methoden aangaven. De resultaten van deze analyses zijn te vinden in de map `data/factor_analyses_simple2023/alternative_factors`.

Alle Factor Analyses zijn uitgevoerd in zowel oblique als ook orthogonale rotatie, wat respectievelijk betekent dat de factoren wel of niet gecorreleerd mogen zijn.

Hieronder volgt een overzicht van de resultaten van de CFA's, en de grafische methoden, als ook van de alternatieve factor analyses. 
De resultaten van de reguliere en alternatieve CFA's zijn weergegeven in de vorm van een tabel, waarbij de factor loadings, item correlaties, en model fit indices zijn weergegeven. 
De grafische methoden zijn weergegeven in de vorm van een grafiek, waarbij de resultaten van de factor analyse, en de principiele componenten analyse zijn weergegeven.

## Resultaten

Over het algemeen, lijken de meeste onderdelen van de aansluiting goed te voldoen aan de eisen van een goede factor analyse.
De vragen van de meeste onderdelen, lijken op een of twee factoren. In tabel 1 staan de aanbevolen nummer van factoren weergegeven, op basis van de verschillende methoden.
Voor de alternatieve factor analyses, is het laagste aantal factoren gebruikt wat hier naar voren is gekomen (zie Lowerst kolom in tabel 1). 
In totaal zijn 9 van de 20 onderdelen onderworpen aan een alternatieve factor analyse.

**Tabel 1: Aanbevolen nummer van factoren per onderdeel**

```{r Recommended Factors, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(factor_analyses[, c("name", "scree_fa", "scree_pc_eigen", "parallel", "lowest")],
  col.names = c("Name", "Scree FA", "Scree PC Eigen", "Parallel", "Lowest")
)
```


### "betekenissen"

#### Grafische Methoden

Hieronder, in figuur 1 en 2, zie je de resultaten van de grafische methoden voor de betekenissen, waarbij de factor analyse en de principiele componenten analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 1: Screeplot Betekenissen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/betekenissen_scree_plot.png)

**Figuur 2: Parallel plot Betekenissen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/betekenissen_parallel_plot.png)


#### Statitische Methoden

```{r Betekenissen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(betekenissen$betekenissen_obli$EPVAL, 3) # < .05
chisq <- betekenissen$betekenissen_obli$chi
betekenissen$betekenissen_obli$EPVAL
# model fit indices
rmsea <- betekenissen$betekenissen_obli$RMSEA[1] # < .06 or .08
tli <- betekenissen$betekenissen_obli$TLI # > 0.95
rms <- betekenissen$betekenissen_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- betekenissen$betekenissen_obli$R2

# Factor loadings
loadings <- betekenissen$betekenissen_obli$loadings # factor loadings
weights <- betekenissen$betekenissen_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- betekenissen$betekenissen_obli$communality # communalities
u2 <- betekenissen$betekenissen_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- betekenissen$betekenissen_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 2: Betekenissen - Model-fit statistieken**

```{r Betekenissen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model-fit resultaten zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA is goed, de TLI is acceptabel, en de CRMS is goed.
Gezien de gevoeligheid van p-waardes in empirische chi-square testen, en de hoge hoeveelheid observaties (N =`r betekenissen$betekenissen_obli$n.obs`), is het verstandiger
de andere fit indexen te hanteren. Tevens laat dit model een relatief goede explained variance zien van ongeveer 65 procent (R-squared: `r factor_r2`).

Als conclusie hier is dat het model goed past, en (dus) een factor voldoende is.


##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 3: Betekenissen - Model-fit statistieken**

```{r Betekenissen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, kunnen twee reccomendaties gemaakt worden.
Een factor loading van een vraag wordt als "goed" gezien zodra deze hoger ligt dan .3. Dit is bij meerdere vragen
niet het geval. Specifiek gaat dit om de volgende vragen (van hoogste naar laagste):

- ASL_betekenissen_010: 0.29
- ASL_betekenissen_001: 0.26
- ASL_betekenissen_009: 0.25
- ASL_betekenissen_008: 0.24
- ASL_betekenissen_015: 0.20
- ASL_betekenissen_002: 0.14

Opvallend is hier dat tussen vraag 008 en vraag 015 een sterke daling is in factor loading. 
Zie figuur 3 voor een grafische weergave:

**Figuur 3: Factor Loadings Betekenissen**

```{r betekenissen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings Betekenissen", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis hiervan, zijn er 2 cut-offs op basis van visuele inspectie van de grafiek. De eerste cut-off is een factor loading van .3, en de tweede cut-off is een factor loading van grofweg ~.2.
Hier wordt geadviseerd om de mildere cut-off te gebruiken, en zodoende slechts 2 vragen te overwegen voor vervanging:

- ASL_betekenissen_015: 0.20
- ASL_betekenissen_002: 0.14


### "cijfers"

Hieronder, in figuur 4 en 5, zie je de resultaten van de grafische methoden voor de cijfers, waarbij de factor analyse en de principiele cijfers analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 4: Screeplot cijfers**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/cijfers_scree_plot.png)

**Figuur 5: Parallel plot cijfers**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/cijfers_parallel_plot.png)


#### Statitische Methoden

```{r cijfers - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(cijfers$cijfers_obli$EPVAL, 3) # < .05
chisq <- cijfers$cijfers_obli$chi

# model fit indices
rmsea <- cijfers$cijfers_obli$RMSEA[1] # < .06 or .08
tli <- cijfers$cijfers_obli$TLI # > 0.95
rms <- cijfers$cijfers_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- cijfers$cijfers_obli$R2

# Factor loadings
loadings <- cijfers$cijfers_obli$loadings # factor loadings
weights <- cijfers$cijfers_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- cijfers$cijfers_obli$communality # communalities
u2 <- cijfers$cijfers_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- cijfers$cijfers_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor cijfers. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 4: cijfers - Model-fit statistieken**

```{r cijfers - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn niet zo positief. De p-waarde van de empirische chi-square test is significant (chi-square = `r chisq`, p < `r p`), de RMSEA is acceptabel, de TLI is slecht, en de CRMS is goed. Wederom,
kan door de hoge nummer van observaties (N = `r cijfers$cijfers_obli$n.obs`) de p-waarde van de empirische chi-square test als minder betrouwbaar worden gezien. Terugverwijzend naar Figuur 1, lijkt het erop
dat wellicht een model met meer dan een factor beter geschikt zou zijn voor de data.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 5: Betekenissen - Model-fit statistieken**

```{r cijfers - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, lijkt de uitkomts voor een een-factor model duidelijk.
Een groot gedeelte van de vragen heeft een zeer goede factor loading, en de communalities zijn hoog. Maar,
in de reeks factor loadings zijn er twee drop-offs te zien. De eerste drop-off is tussen vraag 003 en 016, en de tweede drop-off is tussen vraag 019 en 020.
De eerste drop-off in waardes kan genegeerd worden, gezien de factor loading van vraag 003 nog steeds boven de .3 ligt. De discrepantie hier kan 
ervoor gezorgd hebben dat de model fit indices minder goed zijn bevonden.
De tweede drop-off in waardes is echter wel significant, gezien zowel de vraag voor als na de drop of onder de .3 vallen.
Op basis hiervan word recommendeert om deze 2 vragen (019 en 020) te heroverwegen. Zie figuur 6 voor 
een grafische weergave van de factor Loadings.


**Figuur 6: Factor Loadings Cijfers**
```{r cijfers - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings Cijfers", sub = "Item factor loadings; order based on item factor loadings order")
```


### "componenten"

Hieronder, in figuur 7 en 8, zie je de resultaten van de grafische methoden voor de componenten, waarbij de factor analyse en de principiele componenten analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 7: Screeplot componenten**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/componenten_scree_plot.png)

**Figuur 8: Parallel plot componenten**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/componenten_parallel_plot.png)


#### Statitische Methoden

```{r componenten - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(componenten$componenten_obli$EPVAL, 3) # < .05
chisq <- componenten$componenten_obli$chi

# model fit indices
rmsea <- componenten$componenten_obli$RMSEA[1] # < .06 or .08
tli <- componenten$componenten_obli$TLI # > 0.95
rms <- componenten$componenten_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- componenten$componenten_obli$R2

# Factor loadings
loadings <- componenten$componenten_obli$loadings # factor loadings
weights <- componenten$componenten_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- componenten$componenten_obli$communality # communalities
u2 <- componenten$componenten_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- componenten$componenten_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor componenten. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 6: componenten - Model-fit statistieken**

```{r componenten - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA is goed, de TLI is acceptabel, en de CRMS is goed.
Gezien de nummer van observaties (N =`r componenten$componenten_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 7: Betekenissen - Model-fit statistieken**

```{r componenten - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, lijkt de uitkomts voor een een-factor model duidelijk.
Een groot gedeelte van de vragen heeft een zeer goede factor loading, en de communalities zijn hoog. Slechts 2 vragen hebben een factor loading onder de .3, en deze zijn
vraag 017 en 018. Zie figuur 9 voor een grafische weergave van de factor Loadings. Er wordt geadviseerd om vraag 018 te heroverwegen, 
en, op basis van de nabijheid tot de grenzwaarde van vraag 017, deze allen te herzien mocht verniuwing wenselijk zijn.

**Figuur 9: Factor Loadings componenten**
```{r componenten - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings componenten", sub = "Item factor loadings; order based on item factor loadings order")
```


### "figuren"

Hieronder, in figuur 10 en 11, zie je de resultaten van de grafische methoden voor de figuren, waarbij de factor analyse en de principiele figuren analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 10: Screeplot figuren**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/figuren_scree_plot.png)

**Figuur 11: Parallel plot figuren**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/figuren_parallel_plot.png)


#### Statitische Methoden

```{r figuren - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(figuren$figuren_obli$EPVAL, 3) # < .05
chisq <- figuren$figuren_obli$chi

# model fit indices
rmsea <- figuren$figuren_obli$RMSEA[1] # < .06 or .08
tli <- figuren$figuren_obli$TLI # > 0.95
rms <- figuren$figuren_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- figuren$figuren_obli$R2

# Factor loadings
loadings <- figuren$figuren_obli$loadings # factor loadings
weights <- figuren$figuren_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- figuren$figuren_obli$communality # communalities
u2 <- figuren$figuren_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- figuren$figuren_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 8, zie je de model-fit statistieken van de CFA voor figuren. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 8: figuren - Model-fit statistieken**

```{r figuren - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r figuren$figuren_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 9: Betekenissen - Model-fit statistieken**

```{r figuren - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, zijn er 3 a 4 vragen die heroverwogen kunnen worden, namelijk:

- ASL_figuren_017: 0.2932572
- ASL_figuren_012: 0.2235201
- ASL_figuren_018: 0.2036504
- ASL_figuren_011: 0.1962037

Hierbij kan vraag 017 blijven staan, gezien hoe dichtbij deze bij de grenzwaarde van 0.3 ligt. Opvallend is dat na 017, er een drop-off is in factor loadings.
Zie figuur 12 voor een grafische weergave van de factor Loadings. Hierdoor wordt geadviseerd om zeker vragen 012, 018, en 011 te heroverwegen.

**Figuur 12: Factor Loadings figuren**
```{r figuren - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings figuren", sub = "Item factor loadings; order based on item factor loadings order")
```


### "gedrag_houding_leerkracht"

Hieronder, in figuur 13 en 14, zie je de resultaten van de grafische methoden voor de gedrag_houding_leerkracht, waarbij de factor analyse en de principiele gedrag_houding_leerkracht analyse zijn weergegeven.
Beide gedrag_houding_leerkracht zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 13: Screeplot gedrag_houding_leerkracht**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/gedrag_houding_leerkracht_scree_plot.png)

**Figuur 14: Parallel plot gedrag_houding_leerkracht**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/gedrag_houding_leerkracht_parallel_plot.png)


#### Statitische Methoden

```{r gedrag_houding_leerkracht - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$EPVAL, 3) # < .05
chisq <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$chi

# model fit indices
rmsea <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$RMSEA[1] # < .06 or .08
tli <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$TLI # > 0.95
rms <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$R2

# Factor loadings
loadings <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$loadings # factor loadings
weights <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$communality # communalities
u2 <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 10, zie je de model-fit statistieken van de CFA voor gedrag_houding_leerkracht. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 10: gedrag_houding_leerkracht - Model-fit statistieken**

```{r gedrag_houding_leerkracht - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn goed. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed.
Gezien de nummer van observaties (N =`r gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. 
Maar, normaliter valt de TLI tussen 0 en 1; gezien het resultaat boven 1 ligt, kan dit wijzen op model overfitting of underfitting. In combinatie met de recommended factors
voor gedrag_houding_leerkracht in figuur 1, wordt geadviseerd om het model verder te onderzoeken en te heroverwegen, bijvorobeeld naar een 4-factoren model zoals geadvisseerd in tabel 1.

> @ FLEUR: gezien de vragen van de namen heb ik sterk het vermoeden dat hier inderdaad meerdere factoren zijn. Dit kan snel opgelost worden, en is verder geen probleem, maar dit kunnen we het beste samen doen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 11: Betekenissen - Model-fit statistieken**

```{r gedrag_houding_leerkracht - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("package_origin", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Ondanks de foutieve model fit, blijken de vragen binnen een 1-factor model relatief goed te loaden op een gemeenzame factor. Dit kan betekenen
dat er meerde sub-factoren zouden bestaan binnen de gedrag_houding_leerkracht, maar dat deze allemaal een gemeenzame factor delen.

> @ FLEUR: Als het klopt dat er meerdere sub-factoren zijn, dan is dit een hele positieve uitkomst, en zou het eventueel het waard zijn om de gehele latente structuur te onderzoeken met
> een Structural Equation Model (SEM; hier kun je hierarchise factoren analyseren).

Op basis van de factor loadings, blijken er *maar* 7 van de 112 vragen een factor loading onder de .3 te hebben. Deze zijn:

- ASL_pers_bth_odv_lkr_005 : 0.2854765
- ASL_pers_odv_lkr_001     : 0.2835068
- ASL_pers_bth_lkr_003     : 0.2775591
- ASL_pers_bth_lkr_006     : 0.2644754
- ASL_pers_bth_lkr_007     : 0.2402007
- ASL_pers_odv_lkr_048     : 0.1796332
- ASL_pers_odv_lkr_080     :-0.2688280


Zie figuur 15 en 16 voor een grafische weergave van de factor Loadings.


**Figuur 15: Factor Loadings gedrag_houding_leerkracht**
```{r gedrag_houding_leerkracht - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings gedrag_houding_leerkracht", sub = "Item factor loadings; order based on item factor loadings order")
```

**Figuur 16: Factor Loadings gedrag_houding_leerkracht, zonder negatieve loading**
```{r gedrag_houding_leerkracht - factor loadings plot zoom-in, echo=FALSE, message=FALSE, warning=FALSE}
factor_l <- df$factor_loadings
factor_l <- factor_l[factor_l > 0]
plot <- plot(factor_l)
plot <- lines(factor_l)
plot <- title(main = "Factor Loadings gedrag_houding_leerkracht", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis hiervan, word geadviseerd het model te herovweregen en te heranalyseren. Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om bovengenoemde vragen te heroverwegen,
vooral ASL_pers_odv_lkr_048 en ASL_pers_odv_lkr_080.


### "gedrag_houding_ouder"

Hieronder, in figuur 17 en 18, zie je de resultaten van de grafische methoden voor de gedrag_houding_ouder, waarbij de factor analyse en de principiele gedrag_houding_ouder analyse zijn weergegeven.
Beide gedrag_houding_ouder zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 17: Screeplot gedrag_houding_ouder**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/gedrag_houding_ouder_scree_plot.png)

**Figuur 18: Parallel plot gedrag_houding_ouder**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/gedrag_houding_ouder_parallel_plot.png)


#### Statitische Methoden

```{r gedrag_houding_ouder - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(gedrag_houding_ouder$gedrag_houding_ouder_obli$EPVAL, 3) # < .05
chisq <- gedrag_houding_ouder$gedrag_houding_ouder_obli$chi

# model fit indices
rmsea <- gedrag_houding_ouder$gedrag_houding_ouder_obli$RMSEA[1] # < .06 or .08
tli <- gedrag_houding_ouder$gedrag_houding_ouder_obli$TLI # > 0.95
rms <- gedrag_houding_ouder$gedrag_houding_ouder_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- gedrag_houding_ouder$gedrag_houding_ouder_obli$R2

# Factor loadings
loadings <- gedrag_houding_ouder$gedrag_houding_ouder_obli$loadings # factor loadings
weights <- gedrag_houding_ouder$gedrag_houding_ouder_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- gedrag_houding_ouder$gedrag_houding_ouder_obli$communality # communalities
u2 <- gedrag_houding_ouder$gedrag_houding_ouder_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- gedrag_houding_ouder$gedrag_houding_ouder_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 8, zie je de model-fit statistieken van de CFA voor gedrag_houding_ouder. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 12: gedrag_houding_ouder - Model-fit statistieken**

```{r gedrag_houding_ouder - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn niet goed. Alleen de RMSEA is acceptabel, wat wil zeggen dat de vragen met een-factor relatief goed de data benaderen. Maar dit kan ook komen door een relatieve lage variabiliteit.
Gezien de nummer van observaties (N =`r gedrag_houding_ouder$gedrag_houding_ouder_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een ander model te overwegen

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 13: Betekenissen - Model-fit statistieken**

```{r gedrag_houding_ouder - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("package_origin|intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

In combinatie met de slechte model fit, blijken ook de vragen binnen een 1-factor model relatief slecht te loaden op een gemeenzame factor. Dit wijst 
sterk op meerdere factoren, als ook aanbevolen in tabel 1.

> @ FLEUR: Hier vermoed ik ook dat er meerdere submodellen zijn. Dit kan snel opgelost worden, en is verder geen probleem, maar dit kunnen we het beste samen doen.

De volgende vragen hebben een factor loading onder de .3:
- ASL_pers_sta_odv_lkr_009      :  0.29405428
- ASL_pers_sam_odv_lkr_004      :  0.29049861
- ASL_pers_sta_odv_lkr_003      :  0.27611946
- ASL_pers_odv_lkr_064          :  0.26206467
- ASL_pers_cml_odv_lkr_006      :  0.26110424
- ASL_pers_sta_odv_lkr_006      :  0.24692406
- ASL_pers_sta_odv_lkr_007      :  0.24372876
- ASL_pers_bth_odv_001          :  0.24048961
- ASL_pers_ope_odv_lkr_009      :  0.23695966
- ASL_pers_odv_lkr_028          :  0.23578055
- ASL_pers_bth_odv_lkr_005      :  0.20367628
- ASL_pers_cml_odv_lkr_004      :  0.20049113
- ASL_pers_bth_odv_004          :  0.19125776
- ASL_pers_odv_002              :  0.17062116
- ASL_pers_bth_odv_003          :  0.13675091
- ASL_pers_bth_odv_lkr_009_pilot:  0.09907896
- ASL_pers_odv_lkr_081_pilot    :  0.08118064
- ASL_pers_bth_odv_007          :  0.02702020
- ASL_pers_bth_odv_006          : -0.09481105
- ASL_pers_odv_lkr_080          : -0.21274941

Zie hieronder voor een grafische weergave.

**Figuur 19: Factor Loadings gedrag_houding_ouder**
```{r gedrag_houding_ouder - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings gedrag_houding_ouder", sub = "Item factor loadings; order based on item factor loadings order")
```

Mocht het 1-factor model dwingend gebonden zijn, dan wordt geadviseerd om enkele van de bovengenoemde vragen te heroverwegen.
Met een oog op figuur 19, zou ik adviseren om de volgende vragen te heroverwegen:

- ASL_pers_bth_odv_lkr_005      :  0.20367628
- ASL_pers_cml_odv_lkr_004      :  0.20049113
- ASL_pers_bth_odv_004          :  0.19125776
- ASL_pers_odv_002              :  0.17062116
- ASL_pers_bth_odv_003          :  0.13675091
- ASL_pers_bth_odv_lkr_009_pilot:  0.09907896
- ASL_pers_odv_lkr_081_pilot    :  0.08118064
- ASL_pers_bth_odv_007          :  0.02702020
- ASL_pers_bth_odv_006          : -0.09481105
- ASL_pers_odv_lkr_080          : -0.21274941

Vanaf de eerste vraag in deze lijst begint het sterk te dalen.


### "gedrag_houding"

Hieronder, in figuur 20 en 21, zie je de resultaten van de grafische methoden voor de gedrag_houding, waarbij de factor analyse en de principiele gedrag_houding analyse zijn weergegeven.
Beide gedrag_houding zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 20: Screeplot gedrag_houding**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/gedrag_houding_scree_plot.png)

**Figuur 21: Parallel plot gedrag_houding**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/gedrag_houding_parallel_plot.png)


#### Statitische Methoden

```{r gedrag_houding - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(gedrag_houding$gedrag_houding_obli$EPVAL, 3) # < .05
chisq <- gedrag_houding$gedrag_houding_obli$chi

# model fit indices
rmsea <- gedrag_houding$gedrag_houding_obli$RMSEA[1] # < .06 or .08
tli <- gedrag_houding$gedrag_houding_obli$TLI # > 0.95
rms <- gedrag_houding$gedrag_houding_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- gedrag_houding$gedrag_houding_obli$R2

# Factor loadings
loadings <- gedrag_houding$gedrag_houding_obli$loadings # factor loadings
weights <- gedrag_houding$gedrag_houding_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- gedrag_houding$gedrag_houding_obli$communality # communalities
u2 <- gedrag_houding$gedrag_houding_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- gedrag_houding$gedrag_houding_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 14, zie je de model-fit statistieken van de CFA voor gedrag_houding. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 14: gedrag_houding - Model-fit statistieken**

```{r gedrag_houding - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn niet goed. Alleen de RMSEA is acceptabel, wat wil zeggen dat de vragen met een-factor relatief goed de data benaderen. Maar dit kan ook komen door een relatieve lage variabiliteit.
Gezien de nummer van observaties (N =`r gedrag_houding$gedrag_houding_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een ander model te overwegen

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 15: Betekenissen - Model-fit statistieken**

```{r gedrag_houding - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("package_origin|intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

In combinatie met de slechte model fit, blijken ook de vragen binnen een 1-factor model relatief slecht te loaden op een gemeenzame factor. Dit wijst 
sterk op meerdere factoren, als ook aanbevolen in tabel 1.

> @ FLEUR: Hier vermoed ik ook dat er meerdere subfactoren zijn. Dit kan snel opgelost worden, en is verder geen probleem, maar dit kunnen we het beste samen doen.

De volgende vragen hebben een factor loading onder de .3:

- ASL_pers_lln_078       : 0.2955338
- ASL_pers_lln_059       : 0.2949871
- ASL_pers_lln_005       : 0.2922944
- ASL_pers_lln_051       : 0.2911132
- ASL_pers_lln_096_pilot : 0.2888224
- ASL_pers_lln_063       : 0.2871200
- ASL_pers_lln_003       : 0.2837118
- ASL_pers_lln_074       : 0.2820867
- ASL_pers_lln_088_pilot : 0.2797580
- ASL_pers_lln_066       : 0.2790633
- ASL_pers_lln_089_pilot : 0.2788394
- ASL_pers_lln_083       : 0.2780657
- ASL_pers_lln_052       : 0.2757599
- ASL_pers_lln_087_pilot : 0.2747522
- ASL_pers_lln_065       : 0.2741205
- ASL_pers_lln_007       : 0.2709277
- ASL_pers_lln_109_pilot : 0.2707474
- ASL_pers_lln_061       : 0.2698008
- ASL_pers_lln_035       : 0.2528252
- ASL_pers_lln_023       : 0.2353895
- ASL_pers_lln_021       : 0.2324088
- ASL_pers_lln_108_pilot : 0.2195405
- ASL_pers_lln_043       : 0.2089425
- ASL_pers_lln_040       : 0.1865393
- ASL_pers_lln_048       : 0.1810478
- ASL_pers_lln_085       : 0.1568912
- ASL_pers_lln_064       : 0.1051077
- ASL_pers_lln_006       : 0.1005581

Zie hieronder voor een grafische weergave.

**Figuur 22: Factor Loadings gedrag_houding**
```{r gedrag_houding - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings gedrag_houding", sub = "Item factor loadings; order based on item factor loadings order")
```

Mocht het 1-factor model dwingend gebonden zijn, dan wordt geadviseerd om enkele van de bovengenoemde vragen te heroverwegen.
Met een oog op figuur 19, zou ik adviseren om de volgende vragen te heroverwegen:

- ASL_pers_lln_035       : 0.2528252
- ASL_pers_lln_023       : 0.2353895
- ASL_pers_lln_021       : 0.2324088
- ASL_pers_lln_108_pilot : 0.2195405
- ASL_pers_lln_043       : 0.2089425
- ASL_pers_lln_040       : 0.1865393
- ASL_pers_lln_048       : 0.1810478
- ASL_pers_lln_085       : 0.1568912
- ASL_pers_lln_064       : 0.1051077
- ASL_pers_lln_006       : 0.1005581

Vanaf de eerste vraag in deze lijst begint het sterk te dalen.


### "getallen"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de getallen, waarbij de factor analyse en de principiele getallen analyse zijn weergegeven.
Beide getallen zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 23: Screeplot getallen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/getallen_scree_plot.png)

**Figuur 24: Parallel plot getallen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/getallen_parallel_plot.png)


#### Statitische Methoden

```{r getallen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(getallen$getallen_obli$EPVAL, 3) # < .05
chisq <- getallen$getallen_obli$chi

# model fit indices
rmsea <- getallen$getallen_obli$RMSEA[1] # < .06 or .08
tli <- getallen$getallen_obli$TLI # > 0.95
rms <- getallen$getallen_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- getallen$getallen_obli$R2

# Factor loadings
loadings <- getallen$getallen_obli$loadings # factor loadings
weights <- getallen$getallen_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- getallen$getallen_obli$communality # communalities
u2 <- getallen$getallen_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- getallen$getallen_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 16, zie je de model-fit statistieken van de CFA voor getallen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 16: getallen - Model-fit statistieken**

```{r getallen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r getallen$getallen_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 17: getallen - Model-fit statistieken**

```{r getallen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, zijn er enkele vragen die heroverwogen kunnen worden. Hieronder een lijst van vragen met een factor loading onder de .3:

- ASL7_rekenen_GT_B_0F_005       : 0.25160264
- ASL7_rekenen_GT_A_2F_043_pilot : 0.24456285
- ASL7_rekenen_GT_B_1S_036_pilot : 0.21858648
- ASL7_rekenen_GT_A_0F_001       : 0.21665476
- ASL7_rekenen_GT_B_0F_003       : 0.17859001
- ASL7_rekenen_GT_C_1S_040_pilot : 0.03220107

Hierbij is het opvallend dat de vraag met de eerstvolgende hogere factor loading (ASL7_rekenen_GT_A_1F_016 ) een grote sprong maakt naar ~3.2. Zodoende lijken 
de genoemde vragen niet goed te passen bij de factor. Zie hieronder voor een grafische weergave.

**Figuur 25: Factor Loadings getallen**
```{r getallen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings getallen", sub = "Item factor loadings; order based on item factor loadings order")
```


### "interesse"

Hieronder, in figuur 26 en 27, zie je de resultaten van de grafische methoden voor de interesse, waarbij de factor analyse en de principiele interesse analyse zijn weergegeven.
Beide interesse zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 26: Screeplot interesse**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/interesse_scree_plot.png)

**Figuur 27: Parallel plot interesse**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/interesse_parallel_plot.png)


#### Statitische Methoden

```{r interesse - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(interesse$interesse_obli$EPVAL, 3) # < .05
chisq <- interesse$interesse_obli$chi

# model fit indices
rmsea <- interesse$interesse_obli$RMSEA[1] # < .06 or .08
tli <- interesse$interesse_obli$TLI # > 0.95
rms <- interesse$interesse_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- interesse$interesse_obli$R2

# Factor loadings
loadings <- interesse$interesse_obli$loadings # factor loadings
weights <- interesse$interesse_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- interesse$interesse_obli$communality # communalities
u2 <- interesse$interesse_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- interesse$interesse_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 16, zie je de model-fit statistieken van de CFA voor interesse. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 18: interesse - Model-fit statistieken**

```{r interesse - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Poor", "Poor", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Alle model fit indices zijn slecht. De p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`) is significant, wat betekent dat het model niet goed past. De alternatieve model fit indices vallen allen onder hun cut-off's.
Gezien de nummer van observaties (N =`r interesse$interesse_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het model te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 19: interesse - Model-fit statistieken**

```{r interesse - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, zijn er enkele vragen die heroverwogen kunnen worden. Hieronder een lijst van vragen met een factor loading onder de .3:

- ASL_interesse_001...5 : 0.2994889
- ASL_interesse_001...6 : 0.2994889
- ASL_interesse_022...47: 0.2905295
- ASL_interesse_022...48: 0.2905295
- ASL_interesse_004...12: 0.2884302
- ASL_interesse_004...11: 0.2884302
- ASL_interesse_024...51: 0.2846811
- ASL_interesse_024...52: 0.2846811
- ASL_interesse_027...57: 0.2812666
- ASL_interesse_027...58: 0.2812666
- ASL_interesse_005...14: 0.2783642
- ASL_interesse_005...13: 0.2783642
- ASL_interesse_002...8 : 0.2688856
- ASL_interesse_002...7 : 0.2688856
- ASL_interesse_018...39: 0.2403395
- ASL_interesse_018...40: 0.2403395

De vragen die boven .3 vallen hebben geen grote afstand van ASL_interesse_001...5 m.b.t. factor loading. Zie hieronder voor een grafische weergave:

**Figuur 28: Factor Loadings interesse**
```{r interesse - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings interesse", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de grafiek, de factor loadings, als ook de model fit indices, wordt geadviseerd het model te heroverwegen.
Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om enkele van de bovengenoemde vragen te heroverwegen, en zelfs te kijken naar de vragen
die onder drop-off zitten. Deze lijkt hier plaats te vinden:

- ASL_interesse_030...64: 0.3747033
- ASL_interesse_026...55: 0.3387198


### "leestekens"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de leestekens, waarbij de factor analyse en de principiele leestekens analyse zijn weergegeven.
Beide leestekens zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 29: Screeplot leestekens**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/leestekens_scree_plot.png)

**Figuur 30: Parallel plot leestekens**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/leestekens_parallel_plot.png)


#### Statitische Methoden

```{r leestekens - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(leestekens$leestekens_obli$EPVAL, 3) # < .05
chisq <- leestekens$leestekens_obli$chi

# model fit indices
rmsea <- leestekens$leestekens_obli$RMSEA[1] # < .06 or .08
tli <- leestekens$leestekens_obli$TLI # > 0.95
rms <- leestekens$leestekens_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- leestekens$leestekens_obli$R2

# Factor loadings
loadings <- leestekens$leestekens_obli$loadings # factor loadings
weights <- leestekens$leestekens_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- leestekens$leestekens_obli$communality # communalities
u2 <- leestekens$leestekens_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- leestekens$leestekens_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor leestekens. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.


**Tabel 20: leestekens - Model-fit statistieken**

```{r leestekens - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r leestekens$leestekens_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 21: leestekens - Model-fit statistieken**

```{r leestekens - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings is er slechts een vraag die heroverwogen kan worden:

- ASL7_taalverzorging_LT_1F_010: 0.2575232

De andere vragen hebben een factor loading boven de .3. Zie hieronder voor een grafische weergave. Wel is het opvallend dat zelfs
de "beste" vraag een relatief lage factor loading van 0.43 heeft.

**Figuur 31: Factor Loadings leestekens**
```{r leestekens - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings leestekens", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de resultate wordt geadviseerd om ASL7_taalverzorging_LT_1F_010 te herevalueren, als ook te onderzoeken
waarom alle vragen relatief lage factor loadings hebben. Het 1-factor model is hier acceptabel.


### "lezen_deel1"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de lezen_deel1, waarbij de factor analyse en de principiele lezen_deel1 analyse zijn weergegeven.
Beide lezen_deel1 zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot lezen_deel1**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/lezen_deel1_scree_plot.png)

**Figuur 33: Parallel plot lezen_deel1**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/lezen_deel1_parallel_plot.png)


#### Statitische Methoden

```{r lezen_deel1 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(lezen_deel1$lezen_deel1_obli$EPVAL, 3) # < .05
chisq <- lezen_deel1$lezen_deel1_obli$chi

# model fit indices
rmsea <- lezen_deel1$lezen_deel1_obli$RMSEA[1] # < .06 or .08
tli <- lezen_deel1$lezen_deel1_obli$TLI # > 0.95
rms <- lezen_deel1$lezen_deel1_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- lezen_deel1$lezen_deel1_obli$R2

# Factor loadings
loadings <- lezen_deel1$lezen_deel1_obli$loadings # factor loadings
weights <- lezen_deel1$lezen_deel1_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- lezen_deel1$lezen_deel1_obli$communality # communalities
u2 <- lezen_deel1$lezen_deel1_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- lezen_deel1$lezen_deel1_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor lezen_deel1. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: lezen_deel1 - Model-fit statistieken**

```{r lezen_deel1 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r lezen_deel1$lezen_deel1_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: lezen_deel1 - Model-fit statistieken**

```{r lezen_deel1 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_lezen_LV_bomen_2F_010     : 0.2977406
- ASL_lezen_LV_bomen_2F_009     : 0.2749878
- ASL7_lezen_LV_OCHTEND_2F_001  : 0.2640225
- ASL7_lezen_LV_SUPERSOEP_1F_004: 0.2507747
- ASL7_lezen_LV_SUPERSOEP_1F_006: 0.1975091
- ASL7_lezen_LV_OCHTEND_2F_009  : 0.1638474
- ASL7_lezen_LV_SUPERSOEP_1F_001: 0.1201216

De eerstvolgende vraag ASL7_lezen_LV_APENKOOI_0F_006, boven .3 zit er relatief dichtbij (0.3096842), en kan eventueel ook heroverwogen worden bij noodzaak. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings lezen_deel1**
```{r lezen_deel1 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings lezen_deel1", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de grafische weergaves lijkt er een sterke drop-off te zijn tussen de 4e en 3e vraag. Zodoende 
wordt geadviseerd om op zijn minst de volgende vragen te heroverwegen:

- ASL7_lezen_LV_SUPERSOEP_1F_006: 0.1975091
- ASL7_lezen_LV_OCHTEND_2F_009  : 0.1638474
- ASL7_lezen_LV_SUPERSOEP_1F_001: 0.1201216


### "lezen_deel2"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de lezen_deel2, waarbij de factor analyse en de principiele lezen_deel2 analyse zijn weergegeven.
Beide lezen_deel2 zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot lezen_deel2**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/lezen_deel2_scree_plot.png)

**Figuur 33: Parallel plot lezen_deel2**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/lezen_deel2_parallel_plot.png)


#### Statitische Methoden

```{r lezen_deel2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(lezen_deel2$lezen_deel2_obli$EPVAL, 3) # < .05
chisq <- lezen_deel2$lezen_deel2_obli$chi

# model fit indices
rmsea <- lezen_deel2$lezen_deel2_obli$RMSEA[1] # < .06 or .08
tli <- lezen_deel2$lezen_deel2_obli$TLI # > 0.95
rms <- lezen_deel2$lezen_deel2_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- lezen_deel2$lezen_deel2_obli$R2

# Factor loadings
loadings <- lezen_deel2$lezen_deel2_obli$loadings # factor loadings
weights <- lezen_deel2$lezen_deel2_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- lezen_deel2$lezen_deel2_obli$communality # communalities
u2 <- lezen_deel2$lezen_deel2_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- lezen_deel2$lezen_deel2_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor lezen_deel2. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: lezen_deel2 - Model-fit statistieken**

```{r lezen_deel2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r lezen_deel2$lezen_deel2_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het model te heroverwegen naar een 2-factor model.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: lezen_deel2 - Model-fit statistieken**

```{r lezen_deel2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_lezen_LV_REIS_2F_007           : 0.2970999
- ASL_lezen_LV_ministerie_1F_008_anker: 0.2775468
- ASL7_lezen_LV_REIS_2F_009           : 0.2717821
- ASL7_lezen_LV_SIBERI_1F_001        : 0.2435888
- ASL7_lezen_LV_FIETSHELM_0F_005      : 0.2387003
- ASL7_lezen_LV_SIBERI_1F_005        : 0.2230726
- ASL7_lezen_LV_REIS_2F_004           : 0.1896519
- ASL7_lezen_LV_SIBERI_1F_008        : 0.1696616

De eerstvolgende vraag zit met een relatief hoge afstand vandaan van .3. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings lezen_deel2**
```{r lezen_deel2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings lezen_deel2", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de grafische weergave is het moeilijk om een "knik" onder .3 te benoemen. Zodoende wordt geadviseerd om bovengenoemde vragen te heroverwegen
naar aanleiding van hun relatieve factor loading (e.g., de twee zwaarstwegende). De grafiek laat wel een sterke knik grofweg op het midden zien,
dit zou verder kunnen duiden naar een 2-factor model, zoals gespecificeerd in tabel 1. 

### "opzoeken"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de opzoeken, waarbij de factor analyse en de principiele opzoeken analyse zijn weergegeven.
Beide opzoeken zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot opzoeken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/opzoeken_scree_plot.png)

**Figuur 33: Parallel plot opzoeken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/opzoeken_parallel_plot.png)


#### Statitische Methoden

```{r opzoeken - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(opzoeken$opzoeken_obli$EPVAL, 3) # < .05
chisq <- opzoeken$opzoeken_obli$chi

# model fit indices
rmsea <- opzoeken$opzoeken_obli$RMSEA[1] # < .06 or .08
tli <- opzoeken$opzoeken_obli$TLI # > 0.95
rms <- opzoeken$opzoeken_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- opzoeken$opzoeken_obli$R2

# Factor loadings
loadings <- opzoeken$opzoeken_obli$loadings # factor loadings
weights <- opzoeken$opzoeken_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- opzoeken$opzoeken_obli$communality # communalities
u2 <- opzoeken$opzoeken_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- opzoeken$opzoeken_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor opzoeken. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: opzoeken - Model-fit statistieken**

```{r opzoeken - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r opzoeken$opzoeken_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het 1-factor model aan te houden. 

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: opzoeken - Model-fit statistieken**

```{r opzoeken - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_lezen_OP_1F_001     : 0.2804330
- ASL_lezen_OP_1F_010_anker: 0.2607216
- ASL7_lezen_OP_1F_011     : 0.2582401
- ASL7_lezen_OP_1F_004     : 0.2390716

De eerstvolgende vraag zit met een relatief hoge afstand vandaan van .3. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings opzoeken**
```{r opzoeken - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings opzoeken", sub = "Item factor loadings; order based on item factor loadings order")
```

Er lijkt een knik te zijn rond .3, waarbij de vragen erboven vrij veel afstand hebben van .3. Gezien de lage hoeveelheid vragen, wordt 
geadviseerd geen vragen te verwijderen, zonder nieuwe vragen toe te voegen.


### "sommenmaken"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de sommenmaken, waarbij de factor analyse en de principiele sommenmaken analyse zijn weergegeven.
Beide sommenmaken zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot sommenmaken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/sommenmaken_scree_plot.png)

**Figuur 33: Parallel plot sommenmaken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/sommenmaken_parallel_plot.png)


#### Statitische Methoden

```{r sommenmaken - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(sommenmaken$sommenmaken_obli$EPVAL, 3) # < .05
chisq <- sommenmaken$sommenmaken_obli$chi

# model fit indices
rmsea <- sommenmaken$sommenmaken_obli$RMSEA[1] # < .06 or .08
tli <- sommenmaken$sommenmaken_obli$TLI # > 0.95
rms <- sommenmaken$sommenmaken_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- sommenmaken$sommenmaken_obli$R2

# Factor loadings
loadings <- sommenmaken$sommenmaken_obli$loadings # factor loadings
weights <- sommenmaken$sommenmaken_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- sommenmaken$sommenmaken_obli$communality # communalities
u2 <- sommenmaken$sommenmaken_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- sommenmaken$sommenmaken_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor sommenmaken. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: sommenmaken - Model-fit statistieken**

```{r sommenmaken - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r sommenmaken$sommenmaken_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het 1-factor model aan te houden. 

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: sommenmaken - Model-fit statistieken**

```{r sommenmaken - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_sommenmaken_008: 0.2677724
- ASL_sommenmaken_004: 0.2441723
- ASL_sommenmaken_005: 0.2338283
- ASL_sommenmaken_013: 0.2323027
- ASL_sommenmaken_003: 0.2243570
- ASL_sommenmaken_002: 0.2039333
- ASL_sommenmaken_006: 0.1777487
- ASL_sommenmaken_001: 0.1696676

De eerstvolgende vraag zit relatief dichtbij ASL_sommenmaken_011 (0.3001889). Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings sommenmaken**
```{r sommenmaken - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings sommenmaken", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de resultaten zijn er relatief veel vragen die zouden kunne worden heroverwogen. Op zijn minst wordt geadviseerd om de volgende vragen te heroverwegen:

- ASL_sommenmaken_002: 0.2039333
- ASL_sommenmaken_006: 0.1777487
- ASL_sommenmaken_001: 0.1696676

Het 1-factor model lijkt verder geschikt te zijn. 


### "spelling"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de spelling, waarbij de factor analyse en de principiele spelling analyse zijn weergegeven.
Beide spelling zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot spelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/spelling_scree_plot.png)

**Figuur 33: Parallel plot spelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/spelling_parallel_plot.png)


#### Statitische Methoden

```{r spelling - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(spelling$spelling_obli$EPVAL, 3) # < .05
chisq <- spelling$spelling_obli$chi

# model fit indices
rmsea <- spelling$spelling_obli$RMSEA[1] # < .06 or .08
tli <- spelling$spelling_obli$TLI # > 0.95
rms <- spelling$spelling_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- spelling$spelling_obli$R2

# Factor loadings
loadings <- spelling$spelling_obli$loadings # factor loadings
weights <- spelling$spelling_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- spelling$spelling_obli$communality # communalities
u2 <- spelling$spelling_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- spelling$spelling_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor spelling. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: spelling - Model-fit statistieken**

```{r spelling - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r spelling$spelling_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: spelling - Model-fit statistieken**

```{r spelling - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_taalverzorging_SP_1F_019     : 0.29902933
- ASL7_taalverzorging_SP_3F_035     : 0.29207565
- ET2020_taalverzorging_SP_3F_181   : 0.29097813
- ET2020_taalverzorging_SP_2F_186   : 0.28844970
- ASL7_taalverzorging_SP_2F_026     : 0.28383578
- ASL7_taalverzorging_SP_1F_013     : 0.27445663
- ASL7_taalverzorging_SP_1F_014     : 0.26654976
- ASL7_taalverzorging_SP_2F_027     : 0.26154982
- ASL7_taalverzorging_SP_3F_040     : 0.26056329
- ET2020_taalverzorging_SP_3F_129   : 0.24472335
- ASL7_taalverzorging_SP_2F_024     : 0.24049896
- ET2020_taalverzorging_SP_2F_169   : 0.23335814
- ASL7_taalverzorging_SP_1F_012     : 0.21617561
- ASL7_taalverzorging_SP_2F_029     : 0.20730055
- ASL7_taalverzorging_SP_1F_015     : 0.20651106
- ASL7_taalverzorging_SP_3F_037     : 0.20186626
- ET2020_taalverzorging_SP_3F_118   : 0.19400708
- ASL_taalverzorging_SP_3F_019_anker: 0.18415803
- ET2020_taalverzorging_SP_1F_179   : 0.17539152
- ET2020_taalverzorging_SP_3F_139   : 0.16634742
- ET2020_taalverzorging_SP_1F_143   : 0.16524097
- ASL7_taalverzorging_SP_2F_028     : 0.16178587
- ET2020_taalverzorging_SP_1F_178   : 0.14975351
- ASL7_taalverzorging_SP_2F_031     : 0.11661916
- ET2020_taalverzorging_SP_3F_182   : 0.11002456
- ET2020_taalverzorging_SP_3F_150   :-0.02495911

Door de hoeveelheid vragen, als ook reccomended factors van tabel 1, wordt geadviseerd om het model te heroverwegen. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings spelling**
```{r spelling - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
```

Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd op zijn minst de volgende vragen te heroverwegen:

- ASL7_taalverzorging_SP_2F_031     : 0.11661916
- ET2020_taalverzorging_SP_3F_182   : 0.11002456
- ET2020_taalverzorging_SP_3F_150   :-0.02495911


### "verbanden"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de verbanden, waarbij de factor analyse en de principiele verbanden analyse zijn weergegeven.
Beide verbanden zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot verbanden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/verbanden_scree_plot.png)

**Figuur 33: Parallel plot verbanden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/verbanden_parallel_plot.png)


#### Statitische Methoden

```{r verbanden - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(verbanden$verbanden_obli$EPVAL, 3) # < .05
chisq <- verbanden$verbanden_obli$chi

# model fit indices
rmsea <- verbanden$verbanden_obli$RMSEA[1] # < .06 or .08
tli <- verbanden$verbanden_obli$TLI # > 0.95
rms <- verbanden$verbanden_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- verbanden$verbanden_obli$R2

# Factor loadings
loadings <- verbanden$verbanden_obli$loadings # factor loadings
weights <- verbanden$verbanden_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- verbanden$verbanden_obli$communality # communalities
u2 <- verbanden$verbanden_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- verbanden$verbanden_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor verbanden. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorverbandenen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: verbanden - Model-fit statistieken**

```{r verbanden - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r verbanden$verbanden_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: verbanden - Model-fit statistieken**

```{r verbanden - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_rekenen_VB_B_1F_04 : 0.2861945
- ASL7_rekenen_VB_C_1F_011: 0.2843113
- ASL7_rekenen_VB_A_1F_02 : 0.2619753
- ASL7_rekenen_VB_C_1S_022: 0.2128768
- ASL7_rekenen_VB_B_2F_030: 0.2004990
- ASL7_rekenen_VB_C_1F_010: 0.1430689

Door de hoeveelheid vragen, als ook reccomended factors van tabel 1, wordt geadviseerd om het model niet te heroverwegen. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings verbanden**
```{r verbanden - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings verbanden", sub = "Item factor loadings; order based on item factor loadings order")
```

Uiteindleijk wordt geadviseerd op zijn minst de volgende vragen te heroverwegen:

- ASL7_rekenen_VB_C_1S_022: 0.2128768
- ASL7_rekenen_VB_B_2F_030: 0.2004990
- ASL7_rekenen_VB_C_1F_010: 0.1430689


### "verhoudingen"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de verhoudingen, waarbij de factor analyse en de principiele verhoudingen analyse zijn weergegeven.
Beide verhoudingen zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot verhoudingen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/verhoudingen_scree_plot.png)

**Figuur 33: Parallel plot verhoudingen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/verhoudingen_parallel_plot.png)


#### Statitische Methoden

```{r verhoudingen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(verhoudingen$verhoudingen_obli$EPVAL, 3) # < .05
chisq <- verhoudingen$verhoudingen_obli$chi

# model fit indices
rmsea <- verhoudingen$verhoudingen_obli$RMSEA[1] # < .06 or .08
tli <- verhoudingen$verhoudingen_obli$TLI # > 0.95
rms <- verhoudingen$verhoudingen_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- verhoudingen$verhoudingen_obli$R2

# Factor loadings
loadings <- verhoudingen$verhoudingen_obli$loadings # factor loadings
weights <- verhoudingen$verhoudingen_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- verhoudingen$verhoudingen_obli$communality # communalities
u2 <- verhoudingen$verhoudingen_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- verhoudingen$verhoudingen_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor verhoudingen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorverhoudingenen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: verhoudingen - Model-fit statistieken**

```{r verhoudingen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed of acceptabel.
Gezien de nummer van observaties (N =`r verhoudingen$verhoudingen_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: verhoudingen - Model-fit statistieken**

```{r verhoudingen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_rekenen_VH_C_1F_011      : 0.28865080
- ASL7_rekenen_VH_C_2F_037      : 0.27830355
- ASL7_rekenen_VH_C_2F_036_pilot:-0.01233643
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings verhoudingen**
```{r verhoudingen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings verhoudingen", sub = "Item factor loadings; order based on item factor loadings order")
```


### "verschillen"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de verschillen, waarbij de factor analyse en de principiele verschillen analyse zijn weergegeven.
Beide verschillen zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot verschillen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/verschillen_scree_plot.png)

**Figuur 33: Parallel plot verschillen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/verschillen_parallel_plot.png)


#### Statitische Methoden

```{r verschillen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(verschillen$verschillen_obli$EPVAL, 3) # < .05
chisq <- verschillen$verschillen_obli$chi

# model fit indices
rmsea <- verschillen$verschillen_obli$RMSEA[1] # < .06 or .08
tli <- verschillen$verschillen_obli$TLI # > 0.95
rms <- verschillen$verschillen_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- verschillen$verschillen_obli$R2

# Factor loadings
loadings <- verschillen$verschillen_obli$loadings # factor loadings
weights <- verschillen$verschillen_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- verschillen$verschillen_obli$communality # communalities
u2 <- verschillen$verschillen_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- verschillen$verschillen_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor verschillen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorverschillenen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: verschillen - Model-fit statistieken**

```{r verschillen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn relatief positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), RMSEA en CRMS zijn goed en acceptabel, respctievelijk. 
Gezien de nummer van observaties (N =`r verschillen$verschillen_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: verschillen - Model-fit statistieken**

```{r verschillen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_verschillen_010: 0.27244655
- ASL_verschillen_012: 0.26702396
- ASL_verschillen_013: 0.24764260
- ASL_verschillen_019: 0.21416971
- ASL_verschillen_006: 0.13504209
- ASL_verschillen_014: 0.06079612
- ASL_verschillen_021: 0.03880664
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings verschillen**
```{r verschillen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings verschillen", sub = "Item factor loadings; order based on item factor loadings order")
```

Mochten de bovengenoemde vragen te veel zijn om te heroverwegen, dan wordt geadviseerd om op zijn minst de volgende vragen te heroverwegen:

- ASL_verschillen_006: 0.13504209
- ASL_verschillen_014: 0.06079612
- ASL_verschillen_021: 0.03880664


### "werkwoordspelling"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de werkwoordspelling, waarbij de factor analyse en de principiele werkwoordspelling analyse zijn weergegeven.
Beide werkwoordspelling zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot werkwoordspelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/werkwoordspelling_scree_plot.png)

**Figuur 33: Parallel plot werkwoordspelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/werkwoordspelling_parallel_plot.png)


#### Statitische Methoden

```{r werkwoordspelling - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(werkwoordspelling$werkwoordspelling_obli$EPVAL, 3) # < .05
chisq <- werkwoordspelling$werkwoordspelling_obli$chi

# model fit indices
rmsea <- werkwoordspelling$werkwoordspelling_obli$RMSEA[1] # < .06 or .08
tli <- werkwoordspelling$werkwoordspelling_obli$TLI # > 0.95
rms <- werkwoordspelling$werkwoordspelling_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- werkwoordspelling$werkwoordspelling_obli$R2

# Factor loadings
loadings <- werkwoordspelling$werkwoordspelling_obli$loadings # factor loadings
weights <- werkwoordspelling$werkwoordspelling_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- werkwoordspelling$werkwoordspelling_obli$communality # communalities
u2 <- werkwoordspelling$werkwoordspelling_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- werkwoordspelling$werkwoordspelling_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor werkwoordspelling. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorwerkwoordspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: werkwoordspelling - Model-fit statistieken**

```{r werkwoordspelling - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn relatief positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de RMSEA en CRMS goed en acceptabel, respctievelijk.
Gezien de nummer van observaties (N =`r werkwoordspelling$werkwoordspelling_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model te overwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: werkwoordspelling - Model-fit statistieken**

```{r werkwoordspelling - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_taalverzorging_WS_2F_023      :  0.29989912
- ASL7_taalverzorging_WS_3F_026      :  0.29195511
- ASL7_taalverzorging_WS_1F_003      :  0.29104952
- ASL7_taalverzorging_WS_2F_015      :  0.26737405
- ASL7_taalverzorging_WS_2F_014      :  0.26040021
- ASL7_taalverzorging_WS_3F_025      :  0.17066334
- ASL7_taalverzorging_WS_1F_009_pilot: -0.04235494
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings werkwoordspelling**
```{r werkwoordspelling - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings werkwoordspelling", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de resultaten, wordt in eerste instantie geadviseerd te kijken naar een 2-factor model.
Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om op zijn minst de volgende vragen te herevalueren:
- ASL7_taalverzorging_WS_3F_025      :  0.17066334
- ASL7_taalverzorging_WS_1F_009_pilot: -0.04235494

En eventueel:

- ASL7_taalverzorging_WS_2F_015      :  0.26737405
- ASL7_taalverzorging_WS_2F_014      :  0.26040021

De restant van de vragen zitten heel dicht bij de .3 grenz, en kunnen genegeerd worden.


### "woorden"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de woorden, waarbij de factor analyse en de principiele woorden analyse zijn weergegeven.
Beide woorden zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot woorden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/woorden_scree_plot.png)

**Figuur 33: Parallel plot woorden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple2023/fa_graphs/woorden_parallel_plot.png)


#### Statitische Methoden

```{r woorden - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(woorden$woorden_obli$EPVAL, 3) # < .05
chisq <- woorden$woorden_obli$chi

# model fit indices
rmsea <- woorden$woorden_obli$RMSEA[1] # < .06 or .08
tli <- woorden$woorden_obli$TLI # > 0.95
rms <- woorden$woorden_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- woorden$woorden_obli$R2

# Factor loadings
loadings <- woorden$woorden_obli$loadings # factor loadings
weights <- woorden$woorden_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- woorden$woorden_obli$communality # communalities
u2 <- woorden$woorden_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- woorden$woorden_obli$r
```
##### Model Beoordeling

Hieronder, in tabel 20, zie je de model-fit statistieken van de CFA voor woorden. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorwoordenen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.

**Tabel 22: woorden - Model-fit statistieken**

```{r woorden - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed. 
Gezien de nummer van observaties (N =`r woorden$woorden_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.
- Communalities: de communalities geven aan hoeveel variantie een item deelt met andere items. Hoe hoger de communalities, hoe meer variantie een item deelt met andere items. Een hoge communaliteit betekent dat een item goed bij de factor past.
- Uniquenesses: de uniquenesses geven aan hoeveel variantie een item niet deelt met andere items. Hoe hoger de uniquenesses, hoe meer variantie een item niet deelt met andere items. Een hoge uniqueness betekent dat een item niet goed bij de factor past.

**Tabel 23: woorden - Model-fit statistieken**

```{r woorden - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings = loadings,
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[!grepl("intro", df$naam, ignore.case = TRUE), ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading", "Factor Weights", "Communality", "Uniqueness"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_woorden_015: 0.2914034
- ASL_woorden_006: 0.2792282
- ASL_woorden_008: 0.2782458
- ASL_woorden_003: 0.2761916
- ASL_woorden_002: 0.2548994
- ASL_woorden_001: 0.2512631
- ASL_woorden_012: 0.2419931
- ASL_woorden_009: 0.1490782
- ASL_woorden_019: 0.1488297
- ASL_woorden_014: 0.1394278
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings woorden**
```{r woorden - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- title(main = "Factor Loadings woorden", sub = "Item factor loadings; order based on item factor loadings order")
```
Op basis van de resultaten, wordt in eerste instantie geadviseerd te kijken naar een 2-factor model.
Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om op zijn minst de volgende vragen te herevalueren:

- ASL_woorden_009: 0.1490782
- ASL_woorden_019: 0.1488297
- ASL_woorden_014: 0.1394278


## Alternatieve Resultaten

```{r alternative results, echo=FALSE, message=FALSE, warning=FALSE}
names <- list.files(here("data/factor_analyses_simple2023/alternative_factors"), full.names = TRUE)
names <- names[grepl(".Rdata", names)]


# Load files
for (file in names) {
  load(file, envir = .GlobalEnv)
  # Rename an object in the global environment
  assign(file_path_sans_ext(basename(file)), item_analyses, envir = .GlobalEnv)
  rm(file)
}
rm(names)
```

Hieronder volgen de alternatieve modellen en diens resultaten. De gekozen nummer factoren komen uit tabel 1.

### Cijfers

Voor Cijfers is er een alternatief model getest, waarbij 2 factoren werden gebruikt. 

```{r cijfers_2 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(cijfers_2$cijfers_obli$EPVAL, 3) # < .05
chisq <- cijfers_2$cijfers_obli$chi

# model fit indices
rmsea <- cijfers_2$cijfers_obli$RMSEA[1] # < .06 or .08
tli <- cijfers_2$cijfers_obli$TLI # > 0.95
rms <- cijfers_2$cijfers_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- cijfers_2$cijfers_obli$R2

# Factor loadings
loadings <- cijfers_2$cijfers_obli$loadings # factor loadings
weights <- cijfers_2$cijfers_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- cijfers_2$cijfers_obli$communality # communalities
u2 <- cijfers_2$cijfers_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- cijfers_2$cijfers_obli$r
```


```{r cijfers_2 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Buiten de p-waarde zijn alle waardes goed of acceptabel. En zijn zodoende beter binnen het 2-factor model in oblique rotatie dan in het 1-factor model.

```{r cijfers_2 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL

# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3, ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Weights - MR1", "Factor Weights - MR1", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 2-factor model blijft slechts een vraag over
die niet goed laadt:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs)
```

Deze vraag liet ook al een slechte lading zien bij het originele 1-factor model. Zodoende, zij het in een 2-factor of 1-factor model, het wordt
geadviseerd deze vraag te herzien. Zie de grafiek hieronder voor specifieke factor loadings van alle vragen.
Hier valt te zien dat deze vraag zowel foor factor en als ook voor factor 2 onder 0.3 valt.


**Figuur 6: Factor Loadings Cijfers**
```{r cijfers_2 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1, col = "red", type = "o")
lines(x, df$factor_loadings2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings Cijfers", sub = "Item factor loadings; order based on item factor loadings order")
```

### gedrag_houding

Voor gedrag_houding is een model getest met 6 factoren.

```{r gedrag_houding_6 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(gedrag_houding_6$gedrag_houding_obli$EPVAL, 3) # < .05
chisq <- gedrag_houding_6$gedrag_houding_obli$chi

# model fit indices
rmsea <- gedrag_houding_6$gedrag_houding_obli$RMSEA[1] # < .06 or .08
tli <- gedrag_houding_6$gedrag_houding_obli$TLI # > 0.95
rms <- gedrag_houding_6$gedrag_houding_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- gedrag_houding_6$gedrag_houding_obli$R2

# Factor loadings
loadings <- gedrag_houding_6$gedrag_houding_obli$loadings # factor loadings
weights <- gedrag_houding_6$gedrag_houding_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- gedrag_houding_6$gedrag_houding_obli$communality # communalities
u2 <- gedrag_houding_6$gedrag_houding_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- gedrag_houding_6$gedrag_houding_obli$r
```


```{r gedrag_houding_6 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Buiten de p-waarde zijn alle waardes goed of acceptabel, waarbij CRMS van Poor naar Good is gegaan, en de TLI hoger is geworden. En zijn zodoende beter binnen het 6-factor model in oblique rotatie dan in het 1-factor model.

```{r gedrag_houding_6 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  factor_loadings3 = loadings[, 3],
  factor_loadings4 = loadings[, 4],
  factor_loadings5 = loadings[, 5],
  factor_loadings6 = loadings[, 6],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL
colnames(df)
# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3 & df$factor_loadings3 < 0.3 & df$factor_loadings4 < 0.3 & df$factor_loadings5 < 0.3 & df$factor_loadings6 < 0.3, ]

# Create table
knitr::kable(df[
  , c("naam", "factor_loadings1", "factor_loadings2", "factor_loadings3", "factor_loadings4", "factor_loadings5", "factor_loadings6")
], col.names = c(
  "Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Loading - MR3", "Factor Loading - MR4", "Factor Loading - MR5", "Factor Loading - MR6"
))

knitr::kable(df[, grepl("naam|weights|communalities|uniqueness", colnames(df))], col.names = c("Naam", "Factor Weights - MR1", "Factor Weights - MR2", "Factor Weights - MR3", "Factor Weights - MR4", "Factor Weights - MR5", "Factor Weights - MR6", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 6 factor model zijn meerdere vragen die niet goed laden:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs[, grepl("factor_loadings", colnames(bad_qs)) | grepl("naam", colnames(bad_qs))])
```

2 van deze vragen (074 en 035) lieten ook al een slechte lading zien op het 1-factor model. Zodoende, zij het in een 6-factor of 1-factor model, het wordt
geadviseerd deze vragen te herzien. Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.
Namelijk is de x-axis nu niet meer de volgorde van de vragen zoals deze in de tabel staan, maar is het nu simpelweg de hoogste naar laagste factor loadings van de vragen op de verschillende vragen.
Gezien de grafiek met 6 factoren te druk is om enkele vragen te identificeren, leek dit een informatievere manier om de loadings van de vragen op de verschillende factoren te illustreren.


**Figuur 6: Factor Loadings gedrag_houding**
```{r gedrag_houding_6 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1[order(df$factor_loadings1, decreasing = TRUE)], col = "red", type = "o")
lines(x, df$factor_loadings2[order(df$factor_loadings2, decreasing = TRUE)], col = "blue", type = "o")
lines(x, df$factor_loadings3[order(df$factor_loadings3, decreasing = TRUE)], col = "green", type = "o")
lines(x, df$factor_loadings4[order(df$factor_loadings4, decreasing = TRUE)], col = "purple", type = "o")
lines(x, df$factor_loadings5[order(df$factor_loadings5, decreasing = TRUE)], col = "orange", type = "o")
lines(x, df$factor_loadings6[order(df$factor_loadings6, decreasing = TRUE)], col = "darkgreen", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3", "Factor 4", "Factor 5", "Factor 6"), col = c("red", "blue", "green", "purple", "orange", "darkgreen"), pch = 21, lty = 1)
title(main = "Factor Loadings gedrag_houding", sub = "Item factor loadings; order based on item factor loadings order")
```

### gedrag_houding_leerkracht

Voor gedrag_houding_leerkracht is een model getest met 4 factoren.

```{r gedrag_houding_leerkracht_4 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$EPVAL, 3) # < .05
chisq <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$chi

# model fit indices
rmsea <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$RMSEA[1] # < .06 or .08
tli <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$TLI # > 0.95
rms <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$R2

# Factor loadings
loadings <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$loadings # factor loadings
weights <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$communality # communalities
u2 <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- gedrag_houding_leerkracht_4$gedrag_houding_leerkracht_obli$r
```


```{r gedrag_houding_leerkracht_4 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Good", "Good", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De fit indices zijn aanzienlijk verbetered, maar het lijkt op een geval van overfitting door de >1 van TLI. Zodoende lijkt het erop 
dat 4 factoren te veel zijn (maar 1 te weinig).

```{r gedrag_houding_leerkracht_4 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  factor_loadings3 = loadings[, 3],
  factor_loadings4 = loadings[, 4],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL
colnames(df)
# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3 & df$factor_loadings3 < 0.3 & df$factor_loadings4 < 0.3 & df$factor_loadings5 < 0.3 & df$factor_loadings6 < 0.3, ]

# Create table
knitr::kable(df[
  , c("naam", "factor_loadings1", "factor_loadings2", "factor_loadings3", "factor_loadings4")
], col.names = c(
  "Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Loading - MR3", "Factor Loading - MR4"
))

knitr::kable(df[, grepl("naam|weights|communalities|uniqueness", colnames(df))], col.names = c("Naam", "Factor Weights - MR1", "Factor Weights - MR2", "Factor Weights - MR3", "Factor Weights - MR4", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 4 factor model zijn geen vragen die niet goed laden:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs[, grepl("factor_loadings", colnames(bad_qs)) | grepl("naam", colnames(bad_qs))])
```

Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.
Namelijk is de x-axis nu niet meer de volgorde van de vragen zoals deze in de tabel staan, maar is het nu simpelweg de hoogste naar laagste factor loadings van de vragen op de verschillende vragen.
Gezien de grafiek met 6 factoren te druk is om enkele vragen te identificeren, leek dit een informatievere manier om de loadings van de vragen op de verschillende factoren te illustreren.

**Figuur 6: Factor Loadings gedrag_houding**
```{r gedrag_houding_leerkracht_4 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1[order(df$factor_loadings1, decreasing = TRUE)], col = "red", type = "o")
lines(x, df$factor_loadings2[order(df$factor_loadings2, decreasing = TRUE)], col = "blue", type = "o")
lines(x, df$factor_loadings3[order(df$factor_loadings3, decreasing = TRUE)], col = "green", type = "o")
lines(x, df$factor_loadings4[order(df$factor_loadings4, decreasing = TRUE)], col = "purple", type = "o")

abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3", "Factor 4"), col = c("red", "blue", "green", "purple"), pch = 21, lty = 1)
title(main = "Factor Loadings gedrag_houding", sub = "Item factor loadings; order based on item factor loadings order")
```

### gedrag_houding_ouder

Voor gedrag_houding_ouder is een model getest met 9 factoren.

```{r gedrag_houding_ouder_9 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(gedrag_houding_ouder_9$gedrag_houding_ouder_obli$EPVAL, 3) # < .05
chisq <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$chi

# model fit indices
rmsea <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$RMSEA[1] # < .06 or .08
tli <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$TLI # > 0.95
rms <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$R2

# Factor loadings
loadings <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$loadings # factor loadings
weights <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$communality # communalities
u2 <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- gedrag_houding_ouder_9$gedrag_houding_ouder_obli$r
```


```{r gedrag_houding_ouder_9 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Alle fit indices zijn aanzienlijk verbeterd, en de RMSEA en CRMS zijn beiden naar een "Good" conclusie verschoven. Dit zou kunnen betekenen dat 9 factoren beter bij de data passen.
Wel is het advies hierbij om te overwegen om de questionnaire te verdelen in kleinere questionnaires, gezien de fit indices nog steeds niet in zijn geheel positief uitvallen met 9 factoren. 

```{r gedrag_houding_ouder_9 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  factor_loadings3 = loadings[, 3],
  factor_loadings4 = loadings[, 4],
  factor_loadings5 = loadings[, 5],
  factor_loadings6 = loadings[, 6],
  factor_loadings7 = loadings[, 7],
  factor_loadings8 = loadings[, 8],
  factor_loadings9 = loadings[, 9],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[df$naam != "package_origin", ]

# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3 & df$factor_loadings3 < 0.3 & df$factor_loadings4 < 0.3 & df$factor_loadings5 < 0.3 & df$factor_loadings6 < 0.3 & df$factor_loadings7 < 0.3 & df$factor_loadings8 < 0.3 & df$factor_loadings9 < 0.3, ]

# Create table
knitr::kable(df[
  , c("naam", "factor_loadings1", "factor_loadings2", "factor_loadings3", "factor_loadings4", "factor_loadings5", "factor_loadings6", "factor_loadings7", "factor_loadings8", "factor_loadings9")
], col.names = c(
  "Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Loading - MR3", "Factor Loading - MR4", "Factor Loading - MR5", "Factor Loading - MR6", "Factor Loading - MR7", "Factor Loading - MR8", "Factor Loading - MR9"
))

knitr::kable(df[, grepl("naam|weights|communalities|uniqueness", colnames(df))], col.names = c("Naam", "Factor Weights - MR1", "Factor Weights - MR2", "Factor Weights - MR3", "Factor Weights - MR4", "Factor Weights - MR5", "Factor Weights - MR6", "Factor Weights - MR7", "Factor Weights - MR8", "Factor Weights - MR9", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 9 factor model zijn de volgende vragen die op geen enkele factor goed laden.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs[, grepl("factor_loadings", colnames(bad_qs)) | grepl("naam", colnames(bad_qs))])
```

1 van deze vragen (0ASL_pers_odv_lkr_080) laadde ook niet goed op het 1-factor model. Zodoende, zij het in een 9-factor of 1-factor model, het wordt
geadviseerd deze vragen te herzien. Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.
Namelijk is de x-axis nu niet meer de volgorde van de vragen zoals deze in de tabel staan, maar is het nu simpelweg de hoogste naar laagste factor loadings van de vragen op de verschillende vragen.
Gezien de grafiek met 6 factoren te druk is om enkele vragen te identificeren, leek dit een informatievere manier om de loadings van de vragen op de verschillende factoren te illustreren.


**Figuur 6: Factor Loadings gedrag_houding**
```{r gedrag_houding_ouder_9 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1[order(df$factor_loadings1, decreasing = TRUE)], col = "red", type = "o")
lines(x, df$factor_loadings2[order(df$factor_loadings2, decreasing = TRUE)], col = "blue", type = "o")
lines(x, df$factor_loadings3[order(df$factor_loadings3, decreasing = TRUE)], col = "green", type = "o")
lines(x, df$factor_loadings4[order(df$factor_loadings4, decreasing = TRUE)], col = "purple", type = "o")
lines(x, df$factor_loadings5[order(df$factor_loadings5, decreasing = TRUE)], col = "orange", type = "o")
lines(x, df$factor_loadings6[order(df$factor_loadings6, decreasing = TRUE)], col = "darkgreen", type = "o")
lines(x, df$factor_loadings7[order(df$factor_loadings7, decreasing = TRUE)], col = "cyan", type = "o")
lines(x, df$factor_loadings8[order(df$factor_loadings8, decreasing = TRUE)], col = "magenta", type = "o")
lines(x, df$factor_loadings9[order(df$factor_loadings9, decreasing = TRUE)], col = "yellow", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3", "Factor 4", "Factor 5", "Factor 6", "Factor 7", "Factor 8", "Factor 9"), col = c("red", "blue", "green", "purple", "orange", "darkgreen", "cyan", "magenta", "yellow"), pch = 21, lty = 1)
title(main = "Factor Loadings gedrag_houding", sub = "Item factor loadings; order based on item factor loadings order")
```


### interesse

Voor interesse is een model getest met 11 factoren.

```{r interesse_11 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(interesse_11$interesse_obli$EPVAL, 3) # < .05
chisq <- interesse_11$interesse_obli$chi

# model fit indices
rmsea <- interesse_11$interesse_obli$RMSEA[1] # < .06 or .08
tli <- interesse_11$interesse_obli$TLI # > 0.95
rms <- interesse_11$interesse_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- interesse_11$interesse_obli$R2

# Factor loadings
loadings <- interesse_11$interesse_obli$loadings # factor loadings
weights <- interesse_11$interesse_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- interesse_11$interesse_obli$communality # communalities
u2 <- interesse_11$interesse_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- interesse_11$interesse_obli$r
```


```{r interesse_11 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Poor", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De fit indices zijn niet verbetered, met uitzondering van de CRMS. Zodoende lijkt het erop dat 11 factoren ook geen goeie fit bereiken.
Op basis hiervan wordt het geadviseerd te kijken naar een factor model tussen 1 en 11, of deze questionnaire op te splitsen. 

```{r interesse_11 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  factor_loadings3 = loadings[, 3],
  factor_loadings4 = loadings[, 4],
  factor_loadings5 = loadings[, 5],
  factor_loadings6 = loadings[, 6],
  factor_loadings7 = loadings[, 7],
  factor_loadings8 = loadings[, 8],
  factor_loadings9 = loadings[, 9],
  factor_loadings10 = loadings[, 10],
  factor_loadings11 = loadings[, 11],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL
df <- df[df$naam != "package_origin", ]

# Filter rows where all factor loadings are lower than 0.3

# Get the column names which contain "factor_loading"
cols <- grep("factor_loading", names(df), value = TRUE)

# Get the rows where all values of the selected columns are lower than .3
rows <- apply(df[cols], 1, function(x) all(x < .3))

# Subset the data frame
bad_qs <- df[rows, grepl("naam|factor_loadings", colnames(df))]
bad_qs
# Create table for factor loadings
knitr::kable(df[
  , c("naam", "factor_loadings1", "factor_loadings2", "factor_loadings3", "factor_loadings4", "factor_loadings5", "factor_loadings6", "factor_loadings7", "factor_loadings8", "factor_loadings9", "factor_loadings10", "factor_loadings11")
], col.names = c(
  "Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Loading - MR3", "Factor Loading - MR4", "Factor Loading - MR5", "Factor Loading - MR6", "Factor Loading - MR7", "Factor Loading - MR8", "Factor Loading - MR9", "Factor Loading - MR10", "Factor Loading - MR11"
))

# Create table for factor weights, communalities, and uniquenesses
knitr::kable(df[, grepl("naam|weights|communalities|uniqueness", colnames(df))], col.names = c(
  "Naam", "Factor Weights - MR1", "Factor Weights - MR2", "Factor Weights - MR3", "Factor Weights - MR4", "Factor Weights - MR5", "Factor Weights - MR6", "Factor Weights - MR7", "Factor Weights - MR8", "Factor Weights - MR9", "Factor Weights - MR10", "Factor Weights - MR11", "Communality", "Uniqueness"
))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing ook niet geheel past. In de oblique 11 factor model zijn de volgende vragen die op geen enkele factor goed laden:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs)
```

Geen van de vragen komen overheen met vragen die voorheen slecht laadde op het 1-factor model. 

Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.
Namelijk is de x-axis nu niet meer de volgorde van de vragen zoals deze in de tabel staan, maar is het nu simpelweg de hoogste naar laagste factor loadings van de vragen op de verschillende vragen.
Gezien de grafiek met 6 factoren te druk is om enkele vragen te identificeren, leek dit een informatievere manier om de loadings van de vragen op de verschillende factoren te illustreren.


**Figuur 6: Factor Loadings gedrag_houding**
```{r interesse_11 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1[order(df$factor_loadings1, decreasing = TRUE)], col = "red", type = "o")
lines(x, df$factor_loadings2[order(df$factor_loadings2, decreasing = TRUE)], col = "blue", type = "o")
lines(x, df$factor_loadings3[order(df$factor_loadings3, decreasing = TRUE)], col = "green", type = "o")
lines(x, df$factor_loadings4[order(df$factor_loadings4, decreasing = TRUE)], col = "purple", type = "o")
lines(x, df$factor_loadings5[order(df$factor_loadings5, decreasing = TRUE)], col = "orange", type = "o")
lines(x, df$factor_loadings6[order(df$factor_loadings6, decreasing = TRUE)], col = "darkgreen", type = "o")
lines(x, df$factor_loadings7[order(df$factor_loadings7, decreasing = TRUE)], col = "cyan", type = "o")
lines(x, df$factor_loadings8[order(df$factor_loadings8, decreasing = TRUE)], col = "magenta", type = "o")
lines(x, df$factor_loadings9[order(df$factor_loadings9, decreasing = TRUE)], col = "yellow", type = "o")
lines(x, df$factor_loadings10[order(df$factor_loadings10, decreasing = TRUE)], col = "pink", type = "o")
lines(x, df$factor_loadings11[order(df$factor_loadings11, decreasing = TRUE)], col = "brown", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3", "Factor 4", "Factor 5", "Factor 6", "Factor 7", "Factor 8", "Factor 9", "Factor 10", "Factor 11"), col = c("red", "blue", "green", "purple", "orange", "darkgreen", "cyan", "magenta", "yellow", "pink", "brown"), pch = 21, lty = 1)
title(main = "Factor Loadings gedrag_houding", sub = "Item factor loadings; order based on item factor loadings order")
```


### lezen_deel1

Voor lezen_deel1 is er een alternatief model getest, waarbij 2 factoren werden gebruikt. 

```{r lezen_deel1_2 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(lezen_deel1_2$lezen_deel1_obli$EPVAL, 3) # < .05
chisq <- lezen_deel1_2$lezen_deel1_obli$chi

# model fit indices
rmsea <- lezen_deel1_2$lezen_deel1_obli$RMSEA[1] # < .06 or .08
tli <- lezen_deel1_2$lezen_deel1_obli$TLI # > 0.95
rms <- lezen_deel1_2$lezen_deel1_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- lezen_deel1_2$lezen_deel1_obli$R2

# Factor loadings
loadings <- lezen_deel1_2$lezen_deel1_obli$loadings # factor loadings
weights <- lezen_deel1_2$lezen_deel1_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- lezen_deel1_2$lezen_deel1_obli$communality # communalities
u2 <- lezen_deel1_2$lezen_deel1_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- lezen_deel1_2$lezen_deel1_obli$r
```


```{r lezen_deel1_2 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Buiten de p-waarde zijn alle waardes goed of acceptabel. En zijn zodoende beter binnen het 2-factor model in oblique rotatie dan in het 1-factor model.

```{r lezen_deel1_2 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL

# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3, ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Weights - MR1", "Factor Weights - MR1", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 2-factor model blijft slechts een vraag over
die niet goed laadt:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs)
```

Van deze vragen, waren de volgende ook al slecht-ladend op het 1-factor model:

- ASL_lezen_LV_bomen_2F_010
- ASL_lezen_LV_bomen_2F_009
- ASL7_lezen_LV_SUPERSOEP_1F_004
- ASL7_lezen_LV_SUPERSOEP_1F_006
- ASL7_lezen_LV_SUPERSOEP_1F_001

Zodoende wordt geadviseerd, ongeacht welk model uiteindelijk gehanteert wordt, deze vragen te heroverwegen. 

Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.


**Figuur 6: Factor Loadings lezen_deel1**
```{r lezen_deel1_2 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1, col = "red", type = "o")
lines(x, df$factor_loadings2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings lezen_deel1", sub = "Item factor loadings; order based on item factor loadings order")
```

### lezen_deel2

Voor lezen_deel2 is er een alternatief model getest, waarbij 2 factoren werden gebruikt. 

```{r lezen_deel2_2 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(lezen_deel2_2$lezen_deel2_obli$EPVAL, 3) # < .05
chisq <- lezen_deel2_2$lezen_deel2_obli$chi

# model fit indices
rmsea <- lezen_deel2_2$lezen_deel2_obli$RMSEA[1] # < .06 or .08
tli <- lezen_deel2_2$lezen_deel2_obli$TLI # > 0.95
rms <- lezen_deel2_2$lezen_deel2_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- lezen_deel2_2$lezen_deel2_obli$R2

# Factor loadings
loadings <- lezen_deel2_2$lezen_deel2_obli$loadings # factor loadings
weights <- lezen_deel2_2$lezen_deel2_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- lezen_deel2_2$lezen_deel2_obli$communality # communalities
u2 <- lezen_deel2_2$lezen_deel2_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- lezen_deel2_2$lezen_deel2_obli$r
```


```{r lezen_deel2_2 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Buiten de p-waarde zijn alle waardes goed of acceptabel. En zijn zodoende beter binnen het 2-factor model in oblique rotatie dan in het 1-factor model.

```{r lezen_deel2_2 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL

# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3, ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Weights - MR1", "Factor Weights - MR1", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 2-factor model blijft slechts een vraag over
die niet goed laadt:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs)
```

Van deze vragen, waren de volgende ook al slecht-ladend op het 1-factor model:

- ASL7_lezen_LV_SIBERI_1F_001  
- ASL7_lezen_LV_FIETSHELM_0F_005
- ASL7_lezen_LV_SIBERI_1F_005  
- ASL7_lezen_LV_SIBERI_1F_008 

Zodoende wordt geadviseerd, ongeacht welk model uiteindelijk gehanteert wordt, deze vragen te heroverwegen. 

Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.


**Figuur 6: Factor Loadings lezen_deel2**
```{r lezen_deel2_2 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1, col = "red", type = "o")
lines(x, df$factor_loadings2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings lezen_deel2", sub = "Item factor loadings; order based on item factor loadings order")
```

### spelling

Voor spelling is er een alternatief model getest, waarbij 3 factoren werden gebruikt. 

```{r spelling_3 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(spelling_3$spelling_obli$EPVAL, 3) # < .05
chisq <- spelling_3$spelling_obli$chi

# model fit indices
rmsea <- spelling_3$spelling_obli$RMSEA[1] # < .06 or .08
tli <- spelling_3$spelling_obli$TLI # > 0.95
rms <- spelling_3$spelling_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- spelling_3$spelling_obli$R2

# Factor loadings
loadings <- spelling_3$spelling_obli$loadings # factor loadings
weights <- spelling_3$spelling_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- spelling_3$spelling_obli$communality # communalities
u2 <- spelling_3$spelling_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- spelling_3$spelling_obli$r
```


```{r spelling_3 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

Buiten de p-waarde zijn alle waardes goed of acceptabel. En zijn zodoende beter binnen het 2-factor model in oblique rotatie dan in het 1-factor model.

```{r spelling_3 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  factor_loadings3 = loadings[, 3],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL

# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3 & df$factor_loadings3 < 0.3, ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Loading - MR3", "Factor Weights - MR1", "Factor Weights - MR2", "Factor Weights - MR3", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 2-factor model blijft slechts een vraag over
die niet goed laadt:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs)
```

Van deze vragen, waren de volgende ook al slecht-ladend op het 1-factor model:

- ET2020_taalverzorging_SP_3F_118   
- ET2020_taalverzorging_SP_3F_129   
- ET2020_taalverzorging_SP_1F_178 
- ET2020_taalverzorging_SP_2F_186  
- ET2020_taalverzorging_SP_2F_169
- ET2020_taalverzorging_SP_3F_150 
- ET2020_taalverzorging_SP_3F_182   
- ET2020_taalverzorging_SP_1F_179
- T2020_taalverzorging_SP_3F_139
- ET2020_taalverzorging_SP_1F_143
- ASL7_taalverzorging_SP_2F_027 
- ASL7_taalverzorging_SP_2F_026   
- ASL7_taalverzorging_SP_2F_031 
- ASL7_taalverzorging_SP_1F_019   
- ASL7_taalverzorging_SP_2F_029    
- ASL7_taalverzorging_SP_2F_028
- ASL7_taalverzorging_SP_1F_014     
  

Zodoende wordt geadviseerd, ongeacht welk model uiteindelijk gehanteert wordt, deze vragen te heroverwegen. 

Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.


**Figuur 6: Factor Loadings spelling**
```{r spelling_3 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1, col = "red", type = "o")
lines(x, df$factor_loadings2, col = "blue", type = "o")
lines(x, df$factor_loadings3, col = "green", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3"), col = c("red", "blue", "green"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
```


### werkwoordspelling


Voor spelling is er een alternatief model getest, waarbij 3 factoren werden gebruikt. 

```{r werkwoordspelling_2 - obli - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# null hypothesis: empirical chi-square
p <- round(werkwoordspelling_2$werkwoordspelling_obli$EPVAL, 3) # < .05
chisq <- werkwoordspelling_2$werkwoordspelling_obli$chi

# model fit indices
rmsea <- werkwoordspelling_2$werkwoordspelling_obli$RMSEA[1] # < .06 or .08
tli <- werkwoordspelling_2$werkwoordspelling_obli$TLI # > 0.95
rms <- werkwoordspelling_2$werkwoordspelling_obli$crms # correct RMS, < 0.08

#  Explained variance
factor_r2 <- werkwoordspelling_2$werkwoordspelling_obli$R2

# Factor loadings
loadings <- werkwoordspelling_2$werkwoordspelling_obli$loadings # factor loadings
weights <- werkwoordspelling_2$werkwoordspelling_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
h2 <- werkwoordspelling_2$werkwoordspelling_obli$communality # communalities
u2 <- werkwoordspelling_2$werkwoordspelling_obli$uniqueness # uniquenesses

# Correlation matrix
corr_matrix <- werkwoordspelling_2$werkwoordspelling_obli$r
```


```{r werkwoordspelling_2 - obli - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
  Result = c(p, rmsea, tli, rms),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De RMSEA en CRMS zijn acceptabel en goed, respectievelijk. De TLI is echter slecht. Zodoende lijkt het erop dat dit model niet beter is dan het 1-factor model.


```{r werkwoordspelling_2 - obli - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = rownames(weights),
  factor_loadings1 = loadings[, 1],
  factor_loadings2 = loadings[, 2],
  weights = weights
)

df$communalities <- h2
df$uniquenesses <- u2

df <- df[order(df$factor_loadings1, decreasing = TRUE), ]
rownames(df) <- NULL

# Filter rows where both columns are lower than 0.3
bad_qs <- df[df$factor_loadings1 < 0.3 & df$factor_loadings2 < 0.3, ]

# Create table
knitr::kable(df, col.names = c("Naam", "Factor Loading - MR1", "Factor Loading - MR2", "Factor Weights - MR1", "Factor Weights - MR2", "Communality", "Uniqueness"))
```

Gezien de factor loadings, lijkt het erop dat deze oplossing beter tot de vragen past. In de oblique 2-factor model blijft slechts een vraag over
die niet goed laadt:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(bad_qs)
```

Van deze vragen, waren de volgende ook al slecht-ladend op het 1-factor model:

- ASL7_taalverzorging_WS_2F_015      
- ASL7_taalverzorging_WS_3F_025      
- ASL7_taalverzorging_WS_1F_009_pilot     

Zodoende wordt geadviseerd, ongeacht welk model uiteindelijk gehanteert wordt, deze vragen te heroverwegen. 

Zie de grafiek hieronder voor specifieke factor loadings van alle vragen. Let op, de grafiek is anders opgebouwd dan de vorige grafieken.


**Figuur 6: Factor Loadings spelling**
```{r werkwoordspelling_2 - obli - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$factor_loadings1)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings1, col = "red", type = "o")
lines(x, df$factor_loadings2, col = "blue", type = "o")
lines(x, df$factor_loadings3, col = "green", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3"), col = c("red", "blue", "green"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
```
