---
title: "Aansluiting Item Analyse"
author: "J.F.J. (Jesse) van Bussel"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  html_document:
    theme: readable
    toc: true # table of contents
    toc_float: true # float: stays up left
    css: ["./css/custom.css", "./css/style_documentation.css"]
---
```{r Environment set-up, echo=FALSE, message=FALSE, warning=FALSE}
# Load files
library(here)
library(tools)
library(lavaan)


names <- list.files(here(paste0("data/factor_analyses", format(Sys.Date(), "%Y"), "/")), full.names = TRUE)
names <- names[grepl(".Rdata", names)]

# Load files
for (file in names) {
  load(file, envir = .GlobalEnv)
  # Rename an object in the global environment
  assign(file_path_sans_ext(basename(file)), factor_analyses, envir = .GlobalEnv)
  rm(file)
}
rm(names)
factor_analyses <- read.csv(here(paste0("data/factor_analyses", format(Sys.Date(), "%Y")), "/recommended_factors.csv"))
```


# Aansluiting Item Analyse

## Introductie

Binnen dit document worden de resultaten van de item analyse voorgelegd. De resultaten zijn voornamelijk gebaseerd op factor-analytische procedures.
Specifiek zijn alle onderdelen van de aansluiting onderworpen aan een confirmatieve factor analyse (CFA). De resultaten van deze analyses zijn te vinden in de map `data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/`. 
De resultaten van de CFA's zijn vervolgens gebruikt om de vragen van de onderdelen van de aansluiting te beoordelen op hun kwaliteit, waar kwaliteit beoordeelt wordt door
een combinatie van factor loadings, itemcorrelaties, en model fit indices. 

Om een beter beeld te krijgen of de hoeveelheid factoren van de onderliggende elementen daadwerkelijk eenduidig genoeg zijn, zijn er exploratieve methodes gebruikt om dit te verder te onderzoeken. Hierbij
zijn een Scree plot, met factor analyse en principiele componenten analyse vergelijk, alsook een parallel analyse gebruikt. De resultaten van deze analyses zijn te vinden in de map `data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs`.
De resultaten van deze grafische methoden zijn gebruikt om de resultaten van de CFA's te ondersteunen, of te ontkrachten. Bij enkele onderdelen is er een alternatieve factor analyse uitgevoerd.
Dit is gedaan voor de onderdelen waarbij de resultaten van de CFA's niet eenduidig waren, en de grafische methoden een hoger nummer aan factoren aangaven. De nieuwe CFA's 
zijn uitgevoerd met het laagst aantal factoren dat de grafische methoden aangaven. De resultaten van deze analyses zijn te vinden in de map `data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/alternative_factors`.

Alle Factor Analyses zijn uitgevoerd in zowel oblique als ook orthogonale rotatie, wat respectievelijk betekent dat de factoren wel of niet gecorreleerd mogen zijn.

Hieronder volgt een overzicht van de resultaten van de CFA's, en de grafische methoden, als ook van de alternatieve factor analyses. 
De resultaten van de reguliere en alternatieve CFA's zijn weergegeven in de vorm van een tabel, waarbij de factor loadings, item correlaties, en model fit indices zijn weergegeven. 
De grafische methoden zijn weergegeven in de vorm van een grafiek, waarbij de resultaten van de factor analyse, en de principiele componenten analyse zijn weergegeven.

## Resultaten

Over het algemeen, lijken de meeste onderdelen van de aansluiting goed te voldoen aan de eisen van een goede factor analyse.
De vragen van de meeste onderdelen, lijken op een of twee factoren. In tabel 1 staan de aanbevolen nummer van factoren weergegeven, op basis van de verschillende methoden.
Voor de alternatieve factor analyses, is het laagste aantal factoren gebruikt wat hier naar voren is gekomen (zie Lowerst kolom in tabel 1). 
In totaal zijn 9 van de 20 onderdelen onderworpen aan een alternatieve factor analyse.

**Tabel 1: Aanbevolen nummer van factoren per onderdeel**

```{r Recommended Factors, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(factor_analyses[, c("name", "scree_fa", "scree_pc_eigen", "parallel", "lowest")],
  col.names = c("Name", "Scree FA", "Scree PC Eigen", "Parallel", "Lowest")
)
```


### "betekenissen"

#### Grafische Methoden

Hieronder, in figuur 1 en 2, zie je de resultaten van de grafische methoden voor de betekenissen, waarbij de factor analyse en de principiele componenten analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 1: Screeplot Betekenissen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/betekenissen_scree_plot.png)

**Figuur 2: Parallel plot Betekenissen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/betekenissen_parallel_plot.png)


#### Statitische Methoden

```{r Betekenissen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(betekenissen$betekenissen_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90

# N
lavInspect(betekenissen$betekenissen_obli, what = "nobs")

# Explained variance
r2 <- inspect(betekenissen$betekenissen_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(betekenissen$betekenissen_obli)[parameterEstimates(betekenissen$betekenissen_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(betekenissen$betekenissen_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 2: Betekenissen - Model-fit statistieken**

```{r Betekenissen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model-fit resultaten zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed of acceptabel. 
Gezien de gevoeligheid van p-waardes in empirische chi-square testen, en de hoge hoeveelheid observaties (N =`r lavInspect(betekenissen$betekenissen_obli, what = "nobs")`), is het verstandiger
de andere fit indexen te hanteren.

Als conclusie hier is dat het model goed past, en (dus) een factor voldoende is.


##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 3: Betekenissen - Model-fit statistieken**

```{r Betekenissen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, kunnen twee reccomendaties gemaakt worden.
Een factor loading van een vraag wordt als "goed" gezien zodra deze hoger ligt dan .3. Dit is bij meerdere vragen
niet het geval. Specifiek gaat dit om de volgende vragen (van hoogste naar laagste):

- ASL_betekenissen_010: 0.29
- ASL_betekenissen_001: 0.26
- ASL_betekenissen_009: 0.25
- ASL_betekenissen_008: 0.24
- ASL_betekenissen_015: 0.20
- ASL_betekenissen_002: 0.14

Opvallend is hier dat tussen vraag 008 en vraag 015 een sterke daling is in factor loading. 
Zie figuur 3 voor een grafische weergave:

**Figuur 3: Factor Loadings Betekenissen**

```{r betekenissen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings Betekenissen", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis hiervan, zijn er 2 cut-offs op basis van visuele inspectie van de grafiek. De eerste cut-off is een factor loading van .3, en de tweede cut-off is een factor loading van grofweg ~.2.
Hier wordt geadviseerd om de mildere cut-off te gebruiken, en zodoende slechts 2 vragen te overwegen voor vervanging:

- ASL_betekenissen_015: 0.20
- ASL_betekenissen_002: 0.14


### "cijfers"

Hieronder, in figuur 4 en 5, zie je de resultaten van de grafische methoden voor de cijfers, waarbij de factor analyse en de principiele cijfers analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 4: Screeplot cijfers**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/cijfers_scree_plot.png)

**Figuur 5: Parallel plot cijfers**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/cijfers_parallel_plot.png)


#### Statitische Methoden

```{r cijfers - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(cijfers$cijfers_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(cijfers$cijfers_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(cijfers$cijfers_obli)[parameterEstimates(cijfers$cijfers_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(cijfers$cijfers_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.



**Tabel 4: cijfers - Model-fit statistieken**

```{r cijfers - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn niet zo positief. De p-waarde van de empirische chi-square test is significant (chi-square = `r chisq`, p < `r p`), de RMSEA is acceptabel, de TLI en CFI zijn slecht, en de CRMS is goed. Wederom,
kan door de hoge nummer van observaties (N = `r lavInspect(cijfers$cijfers_obli, what = "nobs")`) de p-waarde van de empirische chi-square test als minder betrouwbaar worden gezien. Terugverwijzend naar Figuur 1, lijkt het erop
dat wellicht een model met meer dan een factor beter geschikt zou zijn voor de data.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 5: Betekenissen - Model-fit statistieken**

```{r cijfers - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Een groot gedeelte van de vragen heeft een zeer goede factor loading. Maar,
in de reeks factor loadings zijn er twee drop-offs te zien. De eerste drop-off is tussen vraag 003 en 016, en de tweede drop-off is tussen vraag 019 en 020.
De eerste drop-off in waardes kan genegeerd worden, gezien de factor loading van vraag 003 nog steeds boven de .3 ligt. De discrepantie hier kan 
ervoor gezorgd hebben dat de model fit indices minder goed zijn bevonden.
De tweede drop-off in waardes is echter wel significant, gezien zowel de vraag voor als na de drop of onder de .3 vallen.
Op basis hiervan word recommendeert om deze 2 vragen (019 en 020) te heroverwegen. Zie figuur 6 voor 
een grafische weergave van de factor Loadings.


**Figuur 6: Factor Loadings Cijfers**
```{r cijfers - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings Cijfers", sub = "Item factor loadings; order based on item factor loadings order")
```


### "componenten"

Hieronder, in figuur 7 en 8, zie je de resultaten van de grafische methoden voor de componenten, waarbij de factor analyse en de principiele componenten analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 7: Screeplot componenten**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/componenten_scree_plot.png)

**Figuur 8: Parallel plot componenten**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/componenten_parallel_plot.png)


#### Statitische Methoden

```{r componenten - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(componenten$componenten_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(componenten$componenten_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(componenten$componenten_obli)[parameterEstimates(componenten$componenten_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(componenten$componenten_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.



**Tabel 6: componenten - Model-fit statistieken**

```{r componenten - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA is goed, de TLI is acceptabel, en de CRMS is goed.
Gezien de nummer van observaties (N =`r lavInspect(componenten$componenten_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 7: Betekenissen - Model-fit statistieken**

```{r componenten - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, lijkt de uitkomts voor een een-factor model duidelijk.
Een groot gedeelte van de vragen heeft een zeer goede factor loading, en de communalities zijn hoog. Slechts 2 vragen hebben een factor loading onder de .3, en deze zijn
vraag 016 en 018. Zie figuur 9 voor een grafische weergave van de factor Loadings. Er wordt geadviseerd om vraag 018 te heroverwegen, 
en, op basis van de nabijheid tot de grenzwaarde van vraag 017, deze allen te herzien mocht verniuwing wenselijk zijn.

**Figuur 9: Factor Loadings componenten**
```{r componenten - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings componenten", sub = "Item factor loadings; order based on item factor loadings order")
```


### "figuren"

Hieronder, in figuur 10 en 11, zie je de resultaten van de grafische methoden voor de figuren, waarbij de factor analyse en de principiele figuren analyse zijn weergegeven.
Beide figuren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 10: Screeplot figuren**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/figuren_scree_plot.png)

**Figuur 11: Parallel plot figuren**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/figuren_parallel_plot.png)


#### Statitische Methoden

```{r figuren - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(figuren$figuren_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(figuren$figuren_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(figuren$figuren_obli)[parameterEstimates(figuren$figuren_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(figuren$figuren_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.



**Tabel 8: figuren - Model-fit statistieken**

```{r figuren - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor*", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r lavInspect(figuren$figuren_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 9: Betekenissen - Model-fit statistieken**

```{r figuren - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, zijn er 3 a 4 vragen die heroverwogen kunnen worden, namelijk:
- ASL_figuren_017: 0.3059266
- ASL_figuren_012: 0.2619573
- ASL_figuren_011: 0.2564110
- ASL_figuren_018: 0.2457952

Hierbij kan vraag 017 blijven staan, gezien hoe dichtbij deze bij de grenzwaarde van 0.3 ligt. Opvallend is dat na 017, er een drop-off is in factor loadings.
Zie figuur 12 voor een grafische weergave van de factor Loadings. Hierdoor wordt geadviseerd om zeker vragen 012, 018, en 011 te heroverwegen.

**Figuur 12: Factor Loadings figuren**
```{r figuren - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings figuren", sub = "Item factor loadings; order based on item factor loadings order")
```


### "gedrag_houding_leerkracht"
<!-- 
Hieronder, in figuur 13 en 14, zie je de resultaten van de grafische methoden voor de gedrag_houding_leerkracht, waarbij de factor analyse en de principiele gedrag_houding_leerkracht analyse zijn weergegeven.
Beide gedrag_houding_leerkracht zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 13: Screeplot gedrag_houding_leerkracht**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/gedrag_houding_leerkracht_scree_plot.png)

**Figuur 14: Parallel plot gedrag_houding_leerkracht**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/gedrag_houding_leerkracht_parallel_plot.png)


#### Statitische Methoden

# ```{r gedrag_houding_leerkracht - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# fit <- fitMeasures(gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli)
# # null hypothesis: empirical chi-square
# p <- round(fit["pvalue"][[1]], 3)
# chisq <- fit["chisq"][[1]]

# # model fit indices
# rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
# p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
# tli <- fit["tli.robust"][[1]] # > 0.95
# rms <- fit["crmr"][[1]] # correct RMS, < 0.08
# cfi <- fit["cfi.robust"][[1]] # > 0.90


# # Explained variance
# r2 <- inspect(gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli, what = "r2")

# # Factor loadings
# loadings <- parameterEstimates(gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli)[parameterEstimates(gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli)$op == "=~", ][c("rhs", "est")]
# weights <- inspect(gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
# ```
##### Model Beoordeling

##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.



**Tabel 10: gedrag_houding_leerkracht - Model-fit statistieken**

# ```{r gedrag_houding_leerkracht - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
#   Result = c(p, rmsea, tli, rms),
#   Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
#   Conclusion = c("Poor", "Good", "Good", "Good")
# )

# # Create table
# knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
# ```

De model fit indices zijn goed. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = r chisq`, p < r p`), zijn de andere model-fit indices goed.
Gezien de nummer van observaties (N =r gedrag_houding_leerkracht$gedrag_houding_leerkracht_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. 
Maar, normaliter valt de TLI tussen 0 en 1; gezien het resultaat boven 1 ligt, kan dit wijzen op model overfitting of underfitting. In combinatie met de recommended factors
voor gedrag_houding_leerkracht in figuur 1, wordt geadviseerd om het model verder te onderzoeken en te heroverwegen, bijvorobeeld naar een 4-factoren model zoals geadvisseerd in tabel 1.

> @ FLEUR: gezien de vragen van de namen heb ik sterk het vermoeden dat hier inderdaad meerdere factoren zijn. Dit kan snel opgelost worden, en is verder geen probleem, maar dit kunnen we het beste samen doen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 11: Betekenissen - Model-fit statistieken**

# ```{r gedrag_houding_leerkracht - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   naam = loadings$rhs,
#   factor_loadings = weights,
#   weights = loadings$est,
#   r2 = r2
# )

# colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


# df <- df[order(df$factor_loadings, decreasing = TRUE), ]
# rownames(df) <- NULL

# # Create table
# knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
# ```

Ondanks de foutieve model fit, blijken de vragen binnen een 1-factor model relatief goed te loaden op een gemeenzame factor. Dit kan betekenen
dat er meerde sub-factoren zouden bestaan binnen de gedrag_houding_leerkracht, maar dat deze allemaal een gemeenzame factor delen.

> @ FLEUR: Als het klopt dat er meerdere sub-factoren zijn, dan is dit een hele positieve uitkomst, en zou het eventueel het waard zijn om de gehele latente structuur te onderzoeken met
> een Structural Equation Model (SEM; hier kun je hierarchise factoren analyseren).

Op basis van de factor loadings, blijken er *maar* 7 van de 112 vragen een factor loading onder de .3 te hebben. Deze zijn:

- ASL_pers_bth_odv_lkr_005 : 0.2854765
- ASL_pers_odv_lkr_001     : 0.2835068
- ASL_pers_bth_lkr_003     : 0.2775591
- ASL_pers_bth_lkr_006     : 0.2644754
- ASL_pers_bth_lkr_007     : 0.2402007
- ASL_pers_odv_lkr_048     : 0.1796332
- ASL_pers_odv_lkr_080     :-0.2688280


Zie figuur 15 en 16 voor een grafische weergave van de factor Loadings.


**Figuur 15: Factor Loadings gedrag_houding_leerkracht**
# ```{r gedrag_houding_leerkracht - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# plot <- plot(df$factor_loadings)
# plot <- lines(df$factor_loadings)
# plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
# plot <- title(main = "Factor Loadings gedrag_houding_leerkracht", sub = "Item factor loadings; order based on item factor loadings order")
# ```

**Figuur 16: Factor Loadings gedrag_houding_leerkracht, zonder negatieve loading**
# ```{r gedrag_houding_leerkracht - factor loadings plot zoom-in, echo=FALSE, message=FALSE, warning=FALSE}
# factor_l <- df$factor_loadings
# factor_l <- factor_l[factor_l > 0]
# plot <- plot(factor_l)
# plot <- lines(factor_l)
# plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
# plot <- title(main = "Factor Loadings gedrag_houding_leerkracht", sub = "Item factor loadings; order based on item factor loadings order")
# ```

Op basis hiervan, word geadviseerd het model te herovweregen en te heranalyseren. Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om bovengenoemde vragen te heroverwegen,
vooral ASL_pers_odv_lkr_048 en ASL_pers_odv_lkr_080.


### "gedrag_houding_ouder"

Hieronder, in figuur 17 en 18, zie je de resultaten van de grafische methoden voor de gedrag_houding_ouder, waarbij de factor analyse en de principiele gedrag_houding_ouder analyse zijn weergegeven.
Beide gedrag_houding_ouder zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 17: Screeplot gedrag_houding_ouder**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/gedrag_houding_ouder_scree_plot.png)

**Figuur 18: Parallel plot gedrag_houding_ouder**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/gedrag_houding_ouder_parallel_plot.png)


#### Statitische Methoden

# ```{r gedrag_houding_ouder - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# # null hypothesis: empirical chi-square
# p <- round(gedrag_houding_ouder$gedrag_houding_ouder_obli$EPVAL, 3) # < .05
# chisq <- gedrag_houding_ouder$gedrag_houding_ouder_obli$chi

# # model fit indices
# rmsea <- gedrag_houding_ouder$gedrag_houding_ouder_obli$RMSEA[1] # < .06 or .08
# tli <- gedrag_houding_ouder$gedrag_houding_ouder_obli$TLI # > 0.95
# rms <- gedrag_houding_ouder$gedrag_houding_ouder_obli$crms # correct RMS, < 0.08

# #  Explained variance
# factor_r2 <- gedrag_houding_ouder$gedrag_houding_ouder_obli$R2

# # Factor loadings
# loadings <- gedrag_houding_ouder$gedrag_houding_ouder_obli$loadings # factor loadings
# weights <- gedrag_houding_ouder$gedrag_houding_ouder_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
# h2 <- gedrag_houding_ouder$gedrag_houding_ouder_obli$communality # communalities
# u2 <- gedrag_houding_ouder$gedrag_houding_ouder_obli$uniqueness # uniquenesses

# # Correlation matrix
# corr_matrix <- gedrag_houding_ouder$gedrag_houding_ouder_obli$r
# ```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.



**Tabel 12: gedrag_houding_ouder - Model-fit statistieken**

# ```{r gedrag_houding_ouder - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
#   Result = c(p, rmsea, tli, rms),
#   Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
#   Conclusion = c("Poor", "Acceptable", "Poor", "Poor")
# )

# # Create table
# knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
# ```

De model fit indices zijn niet goed. Alleen de RMSEA is acceptabel, wat wil zeggen dat de vragen met een-factor relatief goed de data benaderen. Maar dit kan ook komen door een relatieve lage variabiliteit.
Gezien de nummer van observaties (N =r gedrag_houding_ouder$gedrag_houding_ouder_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een ander model te overwegen

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 13: Betekenissen - Model-fit statistieken**

# ```{r gedrag_houding_ouder - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   naam = loadings$rhs,
#   factor_loadings = weights,
#   weights = loadings$est,
#   r2 = r2
# )

# colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


# df <- df[order(df$factor_loadings, decreasing = TRUE), ]
# rownames(df) <- NULL

# # Create table
# knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
# ```

In combinatie met de slechte model fit, blijken ook de vragen binnen een 1-factor model relatief slecht te loaden op een gemeenzame factor. Dit wijst 
sterk op meerdere factoren, als ook aanbevolen in tabel 1.

> @ FLEUR: Hier vermoed ik ook dat er meerdere submodellen zijn. Dit kan snel opgelost worden, en is verder geen probleem, maar dit kunnen we het beste samen doen.

De volgende vragen hebben een factor loading onder de .3:
- ASL_pers_sta_odv_lkr_009      :  0.29405428
- ASL_pers_sam_odv_lkr_004      :  0.29049861
- ASL_pers_sta_odv_lkr_003      :  0.27611946
- ASL_pers_odv_lkr_064          :  0.26206467
- ASL_pers_cml_odv_lkr_006      :  0.26110424
- ASL_pers_sta_odv_lkr_006      :  0.24692406
- ASL_pers_sta_odv_lkr_007      :  0.24372876
- ASL_pers_bth_odv_001          :  0.24048961
- ASL_pers_ope_odv_lkr_009      :  0.23695966
- ASL_pers_odv_lkr_028          :  0.23578055
- ASL_pers_bth_odv_lkr_005      :  0.20367628
- ASL_pers_cml_odv_lkr_004      :  0.20049113
- ASL_pers_bth_odv_004          :  0.19125776
- ASL_pers_odv_002              :  0.17062116
- ASL_pers_bth_odv_003          :  0.13675091
- ASL_pers_bth_odv_lkr_009_pilot:  0.09907896
- ASL_pers_odv_lkr_081_pilot    :  0.08118064
- ASL_pers_bth_odv_007          :  0.02702020
- ASL_pers_bth_odv_006          : -0.09481105
- ASL_pers_odv_lkr_080          : -0.21274941

Zie hieronder voor een grafische weergave.

**Figuur 19: Factor Loadings gedrag_houding_ouder**
# ```{r gedrag_houding_ouder - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# plot <- plot(df$factor_loadings)
# plot <- lines(df$factor_loadings)
# plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
# plot <- title(main = "Factor Loadings gedrag_houding_ouder", sub = "Item factor loadings; order based on item factor loadings order")
# ```

Mocht het 1-factor model dwingend gebonden zijn, dan wordt geadviseerd om enkele van de bovengenoemde vragen te heroverwegen.
Met een oog op figuur 19, zou ik adviseren om de volgende vragen te heroverwegen:

- ASL_pers_bth_odv_lkr_005      :  0.20367628
- ASL_pers_cml_odv_lkr_004      :  0.20049113
- ASL_pers_bth_odv_004          :  0.19125776
- ASL_pers_odv_002              :  0.17062116
- ASL_pers_bth_odv_003          :  0.13675091
- ASL_pers_bth_odv_lkr_009_pilot:  0.09907896
- ASL_pers_odv_lkr_081_pilot    :  0.08118064
- ASL_pers_bth_odv_007          :  0.02702020
- ASL_pers_bth_odv_006          : -0.09481105
- ASL_pers_odv_lkr_080          : -0.21274941

Vanaf de eerste vraag in deze lijst begint het sterk te dalen.


### "gedrag_houding"

Hieronder, in figuur 20 en 21, zie je de resultaten van de grafische methoden voor de gedrag_houding, waarbij de factor analyse en de principiele gedrag_houding analyse zijn weergegeven.
Beide gedrag_houding zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 20: Screeplot gedrag_houding**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/gedrag_houding_scree_plot.png)

**Figuur 21: Parallel plot gedrag_houding**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/gedrag_houding_parallel_plot.png)


#### Statitische Methoden

# ```{r gedrag_houding - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# # null hypothesis: empirical chi-square
# p <- round(gedrag_houding$gedrag_houding_obli$EPVAL, 3) # < .05
# chisq <- gedrag_houding$gedrag_houding_obli$chi

# # model fit indices
# rmsea <- gedrag_houding$gedrag_houding_obli$RMSEA[1] # < .06 or .08
# tli <- gedrag_houding$gedrag_houding_obli$TLI # > 0.95
# rms <- gedrag_houding$gedrag_houding_obli$crms # correct RMS, < 0.08

# #  Explained variance
# factor_r2 <- gedrag_houding$gedrag_houding_obli$R2

# # Factor loadings
# loadings <- gedrag_houding$gedrag_houding_obli$loadings # factor loadings
# weights <- gedrag_houding$gedrag_houding_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
# h2 <- gedrag_houding$gedrag_houding_obli$communality # communalities
# u2 <- gedrag_houding$gedrag_houding_obli$uniqueness # uniquenesses

# # Correlation matrix
# corr_matrix <- gedrag_houding$gedrag_houding_obli$r
# ```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- 

**Tabel 14: gedrag_houding - Model-fit statistieken**

# ```{r gedrag_houding - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
#   Result = c(p, rmsea, tli, rms),
#   Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
#   Conclusion = c("Poor", "Acceptable", "Poor", "Poor")
# )

# # Create table
# knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
# ```

De model fit indices zijn niet goed. Alleen de RMSEA is acceptabel, wat wil zeggen dat de vragen met een-factor relatief goed de data benaderen. Maar dit kan ook komen door een relatieve lage variabiliteit.
Gezien de nummer van observaties (N =r gedrag_houding$gedrag_houding_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een ander model te overwegen

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 15: Betekenissen - Model-fit statistieken**

# ```{r gedrag_houding - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   naam = loadings$rhs,
#   factor_loadings = weights,
#   weights = loadings$est,
#   r2 = r2
# )

# colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


# df <- df[order(df$factor_loadings, decreasing = TRUE), ]
# rownames(df) <- NULL

# # Create table
# knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
# ```

In combinatie met de slechte model fit, blijken ook de vragen binnen een 1-factor model relatief slecht te loaden op een gemeenzame factor. Dit wijst 
sterk op meerdere factoren, als ook aanbevolen in tabel 1.

> @ FLEUR: Hier vermoed ik ook dat er meerdere subfactoren zijn. Dit kan snel opgelost worden, en is verder geen probleem, maar dit kunnen we het beste samen doen.

De volgende vragen hebben een factor loading onder de .3:

- ASL_pers_lln_078       : 0.2955338
- ASL_pers_lln_059       : 0.2949871
- ASL_pers_lln_005       : 0.2922944
- ASL_pers_lln_051       : 0.2911132
- ASL_pers_lln_096_pilot : 0.2888224
- ASL_pers_lln_063       : 0.2871200
- ASL_pers_lln_003       : 0.2837118
- ASL_pers_lln_074       : 0.2820867
- ASL_pers_lln_088_pilot : 0.2797580
- ASL_pers_lln_066       : 0.2790633
- ASL_pers_lln_089_pilot : 0.2788394
- ASL_pers_lln_083       : 0.2780657
- ASL_pers_lln_052       : 0.2757599
- ASL_pers_lln_087_pilot : 0.2747522
- ASL_pers_lln_065       : 0.2741205
- ASL_pers_lln_007       : 0.2709277
- ASL_pers_lln_109_pilot : 0.2707474
- ASL_pers_lln_061       : 0.2698008
- ASL_pers_lln_035       : 0.2528252
- ASL_pers_lln_023       : 0.2353895
- ASL_pers_lln_021       : 0.2324088
- ASL_pers_lln_108_pilot : 0.2195405
- ASL_pers_lln_043       : 0.2089425
- ASL_pers_lln_040       : 0.1865393
- ASL_pers_lln_048       : 0.1810478
- ASL_pers_lln_085       : 0.1568912
- ASL_pers_lln_064       : 0.1051077
- ASL_pers_lln_006       : 0.1005581

Zie hieronder voor een grafische weergave.

**Figuur 22: Factor Loadings gedrag_houding**
# ```{r gedrag_houding - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# plot <- plot(df$factor_loadings)
# plot <- lines(df$factor_loadings)
# plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
# plot <- title(main = "Factor Loadings gedrag_houding", sub = "Item factor loadings; order based on item factor loadings order")
# ```

Mocht het 1-factor model dwingend gebonden zijn, dan wordt geadviseerd om enkele van de bovengenoemde vragen te heroverwegen.
Met een oog op figuur 19, zou ik adviseren om de volgende vragen te heroverwegen:

- ASL_pers_lln_035       : 0.2528252
- ASL_pers_lln_023       : 0.2353895
- ASL_pers_lln_021       : 0.2324088
- ASL_pers_lln_108_pilot : 0.2195405
- ASL_pers_lln_043       : 0.2089425
- ASL_pers_lln_040       : 0.1865393
- ASL_pers_lln_048       : 0.1810478
- ASL_pers_lln_085       : 0.1568912
- ASL_pers_lln_064       : 0.1051077
- ASL_pers_lln_006       : 0.1005581

Vanaf de eerste vraag in deze lijst begint het sterk te dalen. -->


### "getallen"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de getallen, waarbij de factor analyse en de principiele getallen analyse zijn weergegeven.
Beide getallen zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 23: Screeplot getallen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/getallen_scree_plot.png)

**Figuur 24: Parallel plot getallen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/getallen_parallel_plot.png)


#### Statitische Methoden

```{r getallen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(getallen$getallen_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(getallen$getallen_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(getallen$getallen_obli)[parameterEstimates(getallen$getallen_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(getallen$getallen_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 16: getallen - Model-fit statistieken**

```{r getallen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht en CFI zijn slecht.
Gezien de nummer van observaties (N =`r lavInspect(getallen$getallen_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 17: getallen - Model-fit statistieken**

```{r getallen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings en de communality/uniqueness waardes, zijn er enkele vragen die heroverwogen kunnen worden. Hieronder een lijst van vragen met een factor loading onder de .3:

- ASL7_rekenen_GT_B_0F_005      : 0.2473067
- ASL7_rekenen_GT_A_2F_043_pilot: 0.2396258
- ASL7_rekenen_GT_B_1S_036_pilot: 0.2218636
- ASL7_rekenen_GT_A_0F_001      : 0.2103351
- ASL7_rekenen_GT_B_0F_003      : 0.1749913
- ASL7_rekenen_GT_C_1S_040_pilot: 0.0306448

Hierbij is het opvallend dat de vraag met de eerstvolgende hogere factor loading (ASL7_rekenen_GT_A_1F_016 ) een grote sprong maakt naar ~3.2. Zodoende lijken 
de genoemde vragen niet goed te passen bij de factor. Op zijn minst wordt geadviseerd om vraag ASL7_rekenen_GT_C_1S_040_pilot te herevalueren. Zie hieronder voor een grafische weergave.

**Figuur 25: Factor Loadings getallen**
```{r getallen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings getallen", sub = "Item factor loadings; order based on item factor loadings order")
```

<!-- 
### "interesse"

Hieronder, in figuur 26 en 27, zie je de resultaten van de grafische methoden voor de interesse, waarbij de factor analyse en de principiele interesse analyse zijn weergegeven.
Beide interesse zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 26: Screeplot interesse**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/interesse_scree_plot.png)

**Figuur 27: Parallel plot interesse**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple r format(Sys.Date(), "%Y")`/fa_graphs/interesse_parallel_plot.png)


#### Statitische Methoden

# ```{r interesse - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
# # null hypothesis: empirical chi-square
# p <- round(interesse$interesse_obli$EPVAL, 3) # < .05
# chisq <- interesse$interesse_obli$chi

# # model fit indices
# rmsea <- interesse$interesse_obli$RMSEA[1] # < .06 or .08
# tli <- interesse$interesse_obli$TLI # > 0.95
# rms <- interesse$interesse_obli$crms # correct RMS, < 0.08

# #  Explained variance
# factor_r2 <- interesse$interesse_obli$R2

# # Factor loadings
# loadings <- interesse$interesse_obli$loadings # factor loadings
# weights <- interesse$interesse_obli$weights # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
# h2 <- interesse$interesse_obli$communality # communalities
# u2 <- interesse$interesse_obli$uniqueness # uniquenesses

# # Correlation matrix
# corr_matrix <- interesse$interesse_obli$r
# ```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 18: interesse - Model-fit statistieken**

# ```{r interesse - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS"),
#   Result = c(p, rmsea, tli, rms),
#   Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10"),
#   Conclusion = c("Poor", "Poor", "Poor", "Poor")
# )

# # Create table
# knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
# ```

Alle model fit indices zijn slecht. De p-waarde van de empirische chi-square test (chi-square = r chisq`, p < r p`) is significant, wat betekent dat het model niet goed past. De alternatieve model fit indices vallen allen onder hun cut-off's.
Gezien de nummer van observaties (N =r interesse$interesse_obli$n.obs`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het model te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 19: interesse - Model-fit statistieken**

# ```{r interesse - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# # Create dataframe
# df <- data.frame(
#   naam = loadings$rhs,
#   factor_loadings = weights,
#   weights = loadings$est,
#   r2 = r2
# )

# colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


# df <- df[order(df$factor_loadings, decreasing = TRUE), ]
# rownames(df) <- NULL

# # Create table
# knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
# ```

Op basis van de factor loadings en de communality/uniqueness waardes, zijn er enkele vragen die heroverwogen kunnen worden. Hieronder een lijst van vragen met een factor loading onder de .3:

- ASL_interesse_001...5 : 0.2994889
- ASL_interesse_001...6 : 0.2994889
- ASL_interesse_022...47: 0.2905295
- ASL_interesse_022...48: 0.2905295
- ASL_interesse_004...12: 0.2884302
- ASL_interesse_004...11: 0.2884302
- ASL_interesse_024...51: 0.2846811
- ASL_interesse_024...52: 0.2846811
- ASL_interesse_027...57: 0.2812666
- ASL_interesse_027...58: 0.2812666
- ASL_interesse_005...14: 0.2783642
- ASL_interesse_005...13: 0.2783642
- ASL_interesse_002...8 : 0.2688856
- ASL_interesse_002...7 : 0.2688856
- ASL_interesse_018...39: 0.2403395
- ASL_interesse_018...40: 0.2403395

De vragen die boven .3 vallen hebben geen grote afstand van ASL_interesse_001...5 m.b.t. factor loading. Zie hieronder voor een grafische weergave:

**Figuur 28: Factor Loadings interesse**
# ```{r interesse - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# plot <- plot(df$factor_loadings)
# plot <- lines(df$factor_loadings)
# plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
# plot <- title(main = "Factor Loadings interesse", sub = "Item factor loadings; order based on item factor loadings order")
# ```

Op basis van de grafiek, de factor loadings, als ook de model fit indices, wordt geadviseerd het model te heroverwegen.
Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om enkele van de bovengenoemde vragen te heroverwegen, en zelfs te kijken naar de vragen
die onder drop-off zitten. Deze lijkt hier plaats te vinden:

- ASL_interesse_030...64: 0.3747033
- ASL_interesse_026...55: 0.3387198 -->


### "leestekens"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de leestekens, waarbij de factor analyse en de principiele leestekens analyse zijn weergegeven.
Beide leestekens zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 29: Screeplot leestekens**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/leestekens_scree_plot.png)

**Figuur 30: Parallel plot leestekens**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/leestekens_parallel_plot.png)


#### Statitische Methoden

```{r leestekens - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(leestekens$leestekens_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(leestekens$leestekens_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(leestekens$leestekens_obli)[parameterEstimates(leestekens$leestekens_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(leestekens$leestekens_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 20: leestekens - Model-fit statistieken**

```{r leestekens - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r lavInspect(leestekens$leestekens_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 21: leestekens - Model-fit statistieken**

```{r leestekens - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings is er slechts een vraag die heroverwogen kan worden:

- ASL7_taalverzorging_LT_1F_010:0.2568143

De andere vragen hebben een factor loading boven de .3. Zie hieronder voor een grafische weergave. Wel is het opvallend dat zelfs
de "beste" vraag een relatief lage factor loading van 0.43 heeft.

**Figuur 31: Factor Loadings leestekens**
```{r leestekens - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings leestekens", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de resultate wordt geadviseerd om ASL7_taalverzorging_LT_1F_010 te herevalueren, als ook te onderzoeken
waarom alle vragen relatief lage factor loadings hebben. Het 1-factor model is hier acceptabel.


### "lezen_deel1"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de lezen_deel1, waarbij de factor analyse en de principiele lezen_deel1 analyse zijn weergegeven.
Beide lezen_deel1 zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot lezen_deel1**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/lezen_deel1_scree_plot.png)

**Figuur 33: Parallel plot lezen_deel1**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/lezen_deel1_parallel_plot.png)


#### Statitische Methoden

```{r lezen_deel1 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(lezen_deel1$lezen_deel1_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(lezen_deel1$lezen_deel1_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(lezen_deel1$lezen_deel1_obli)[parameterEstimates(lezen_deel1$lezen_deel1_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(lezen_deel1$lezen_deel1_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.

**Tabel 22: lezen_deel1 - Model-fit statistieken**

```{r lezen_deel1 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r lavInspect(lezen_deel1$lezen_deel1_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om een model met 1 factor te gebruiken.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: lezen_deel1 - Model-fit statistieken**

```{r lezen_deel1 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_lezen_LV_APENKOOI_0F_006 : 0.3092514
- ASL_lezen_LV_bomen_2F_010     : 0.2944582
- ASL_lezen_LV_bomen_2F_009     : 0.2738740
- ASL7_lezen_LV_OCHTEND_2F_001  : 0.2644217
- ASL7_lezen_LV_SUPERSOEP_1F_004: 0.2494930
- ASL7_lezen_LV_SUPERSOEP_1F_006: 0.1959804
- ASL7_lezen_LV_OCHTEND_2F_009  : 0.1651424
- ASL7_lezen_LV_SUPERSOEP_1F_001: 0.1186365

De eerstvolgende vraag ASL7_lezen_LV_APENKOOI_0F_006, boven .3 zit er relatief dichtbij (0.3096842), en kan eventueel ook heroverwogen worden bij noodzaak. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings lezen_deel1**
```{r lezen_deel1 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings lezen_deel1", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de grafische weergaves lijkt er een sterke drop-off te zijn tussen de 4e en 3e vraag. Zodoende 
wordt geadviseerd om op zijn minst de volgende vragen te heroverwegen:

- ASL7_lezen_LV_SUPERSOEP_1F_006: 0.1959804
- ASL7_lezen_LV_OCHTEND_2F_009  : 0.1651424
- ASL7_lezen_LV_SUPERSOEP_1F_001: 0.1186365


### "lezen_deel2"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de lezen_deel2, waarbij de factor analyse en de principiele lezen_deel2 analyse zijn weergegeven.
Beide lezen_deel2 zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot lezen_deel2**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/lezen_deel2_scree_plot.png)

**Figuur 33: Parallel plot lezen_deel2**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/lezen_deel2_parallel_plot.png)


#### Statitische Methoden

```{r lezen_deel2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(lezen_deel2$lezen_deel2_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(lezen_deel2$lezen_deel2_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(lezen_deel2$lezen_deel2_obli)[parameterEstimates(lezen_deel2$lezen_deel2_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(lezen_deel2$lezen_deel2_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.

**Tabel 22: lezen_deel2 - Model-fit statistieken**

```{r lezen_deel2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn minder positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. De RMSEA en CRMS zijn goed, maar de TLI is slecht.
Gezien de nummer van observaties (N =`r lavInspect(lezen_deel2$lezen_deel2_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het model te heroverwegen naar een 2-factor model.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: lezen_deel2 - Model-fit statistieken**

```{r lezen_deel2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_lezen_LV_REIS_2F_007           : 0.2976253
- ASL_lezen_LV_ministerie_1F_008_anker: 0.2778761
- ASL7_lezen_LV_REIS_2F_009           : 0.2733828
- ASL7_lezen_LV_SIBERI_1F_001        : 0.2421779
- ASL7_lezen_LV_FIETSHELM_0F_005      : 0.2378667
- ASL7_lezen_LV_SIBERI_1F_005        : 0.2221975
- ASL7_lezen_LV_REIS_2F_004           : 0.1890827
- ASL7_lezen_LV_SIBERI_1F_008        : 0.1682851


De eerstvolgende vraag zit met een relatief hoge afstand vandaan van .3. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings lezen_deel2**
```{r lezen_deel2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings lezen_deel2", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de grafische weergave is het moeilijk om een "knik" onder .3 te benoemen. Zodoende wordt geadviseerd om bovengenoemde vragen te heroverwegen
naar aanleiding van hun relatieve factor loading (e.g., de twee zwaarstwegende). De grafiek laat wel een sterke knik grofweg op het midden zien,
dit zou verder kunnen duiden naar een 2-factor model, zoals gespecificeerd in tabel 1. 

### "opzoeken"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de opzoeken, waarbij de factor analyse en de principiele opzoeken analyse zijn weergegeven.
Beide opzoeken zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot opzoeken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/opzoeken_scree_plot.png)

**Figuur 33: Parallel plot opzoeken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/opzoeken_parallel_plot.png)


#### Statitische Methoden

```{r opzoeken - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(opzoeken$opzoeken_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(opzoeken$opzoeken_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(opzoeken$opzoeken_obli)[parameterEstimates(opzoeken$opzoeken_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(opzoeken$opzoeken_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: opzoeken - Model-fit statistieken**

```{r opzoeken - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Good", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r lavInspect(opzoeken$opzoeken_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het 1-factor model aan te houden. 

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: opzoeken - Model-fit statistieken**

```{r opzoeken - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_lezen_OP_1F_001     : 0.2779709
- ASL_lezen_OP_1F_010_anker: 0.2625334
- ASL7_lezen_OP_1F_011     : 0.2540318
- ASL7_lezen_OP_1F_004     : 0.2350116

De eerstvolgende vraag zit met een relatief hoge afstand vandaan van .3. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings opzoeken**
```{r opzoeken - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings opzoeken", sub = "Item factor loadings; order based on item factor loadings order")
```

Er lijkt een knik te zijn rond .3, waarbij de vragen erboven vrij veel afstand hebben van .3. Gezien de lage hoeveelheid vragen, wordt 
geadviseerd geen vragen te verwijderen, zonder nieuwe vragen toe te voegen.


### "sommenmaken"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de sommenmaken, waarbij de factor analyse en de principiele sommenmaken analyse zijn weergegeven.
Beide sommenmaken zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot sommenmaken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/sommenmaken_scree_plot.png)

**Figuur 33: Parallel plot sommenmaken**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/sommenmaken_parallel_plot.png)


#### Statitische Methoden

```{r sommenmaken - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(sommenmaken$sommenmaken_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(sommenmaken$sommenmaken_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(sommenmaken$sommenmaken_obli)[parameterEstimates(sommenmaken$sommenmaken_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(sommenmaken$sommenmaken_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: sommenmaken - Model-fit statistieken**

```{r sommenmaken - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn niet positief, met uitzondering van RMSEA en CRMS.
Gezien de nummer van observaties (N =`r lavInspect(sommenmaken$sommenmaken_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het 1-factor model aan te houden. 

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: sommenmaken - Model-fit statistieken**

```{r sommenmaken - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er geen vragen die heroverwogen hoeven te worden. Wel lijkt het model
niet goed te passen, en is het te heroverwegen een andere model structuur toe te passen (e.g., second-order factors).



**Figuur 34: Factor Loadings sommenmaken**
```{r sommenmaken - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings sommenmaken", sub = "Item factor loadings; order based on item factor loadings order")
```



### "spelling"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de spelling, waarbij de factor analyse en de principiele spelling analyse zijn weergegeven.
Beide spelling zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot spelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/spelling_scree_plot.png)

**Figuur 33: Parallel plot spelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/spelling_parallel_plot.png)


#### Statitische Methoden

```{r spelling - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(spelling$spelling_obli) # warning: takes very long.


# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(spelling$spelling_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(spelling$spelling_obli)[parameterEstimates(spelling$spelling_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(spelling$spelling_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: spelling - Model-fit statistieken**

```{r spelling - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r lavInspect(spelling$spelling_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: spelling - Model-fit statistieken**

```{r spelling - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ET2020_taalverzorging_SP_1F_100   :  0.2891204
- ASL7_taalverzorging_SP_1F_019     :  0.2849466
- ASL_taalverzorging_SP_2F_018_anker:  0.2788721
- ET2020_taalverzorging_SP_2F_186   :  0.2787370
- ET2020_taalverzorging_SP_3F_181   :  0.2769121
- ASL7_taalverzorging_SP_2F_026     :  0.2708804
- ASL7_taalverzorging_SP_3F_035     :  0.2696808
- ASL7_taalverzorging_SP_2F_027     :  0.2565016
- ASL7_taalverzorging_SP_1F_013     :  0.2545161
- ASL7_taalverzorging_SP_1F_014     :  0.2506190
- ASL7_taalverzorging_SP_3F_040     :  0.2386501
- ET2020_taalverzorging_SP_3F_129   :  0.2363504
- ET2020_taalverzorging_SP_2F_169   :  0.2250410
- ASL7_taalverzorging_SP_2F_024     :  0.2226581
- ASL7_taalverzorging_SP_2F_029     :  0.1968821
- ASL7_taalverzorging_SP_1F_012     :  0.1939577
- ASL7_taalverzorging_SP_1F_015     :  0.1931994
- ET2020_taalverzorging_SP_3F_118   :  0.1922116
- ASL7_taalverzorging_SP_3F_037     :  0.1880158
- ASL_taalverzorging_SP_3F_019_anker:  0.1702789
- ET2020_taalverzorging_SP_1F_179   :  0.1680973
- ET2020_taalverzorging_SP_3F_139   :  0.1585453
- ET2020_taalverzorging_SP_1F_143   :  0.1555871
- ASL7_taalverzorging_SP_2F_028     :  0.1477771
- ET2020_taalverzorging_SP_1F_178   :  0.1456397
- ASL7_taalverzorging_SP_2F_031     :  0.1091965
- ET2020_taalverzorging_SP_3F_182   :  0.1055882
- ET2020_taalverzorging_SP_3F_150   : -0.0283571

Door de hoeveelheid vragen, als ook reccomended factors van tabel 1, wordt geadviseerd om het model te heroverwegen. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings spelling**
```{r spelling - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
```

Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd op zijn minst de volgende vragen te heroverwegen:

- ASL7_taalverzorging_SP_2F_031     : 0.11661916
- ET2020_taalverzorging_SP_3F_182   : 0.11002456
- ET2020_taalverzorging_SP_3F_150   :-0.02495911


### "verbanden"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de verbanden, waarbij de factor analyse en de principiele verbanden analyse zijn weergegeven.
Beide verbanden zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot verbanden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/verbanden_scree_plot.png)

**Figuur 33: Parallel plot verbanden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/verbanden_parallel_plot.png)


#### Statitische Methoden

```{r verbanden - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(verbanden$verbanden_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(verbanden$verbanden_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(verbanden$verbanden_obli)[parameterEstimates(verbanden$verbanden_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(verbanden$verbanden_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: verbanden - Model-fit statistieken**

```{r verbanden - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed.
Gezien de nummer van observaties (N =`r lavInspect(verbanden$verbanden_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: verbanden - Model-fit statistieken**

```{r verbanden - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_rekenen_VB_B_1F_05 : 0.2996997
- ASL7_rekenen_VB_C_1F_011: 0.2856471
- ASL7_rekenen_VB_B_1F_04 : 0.2855949
- ASL7_rekenen_VB_A_1F_02 : 0.2704764
- ASL7_rekenen_VB_C_1S_022: 0.2006098
- ASL7_rekenen_VB_B_2F_030: 0.1850364
- ASL7_rekenen_VB_C_1F_010: 0.1294791

Door de hoeveelheid vragen, als ook reccomended factors van tabel 1, wordt geadviseerd om het model niet te heroverwegen. Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings verbanden**
```{r verbanden - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings verbanden", sub = "Item factor loadings; order based on item factor loadings order")
```

Uiteindleijk wordt geadviseerd op zijn minst de volgende vragen te heroverwegen:

- ASL7_rekenen_VB_C_1S_022: 0.2128768
- ASL7_rekenen_VB_B_2F_030: 0.2004990
- ASL7_rekenen_VB_C_1F_010: 0.1430689


### "verhoudingen"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de verhoudingen, waarbij de factor analyse en de principiele verhoudingen analyse zijn weergegeven.
Beide verhoudingen zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot verhoudingen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/verhoudingen_scree_plot.png)

**Figuur 33: Parallel plot verhoudingen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/verhoudingen_parallel_plot.png)


#### Statitische Methoden

```{r verhoudingen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(verhoudingen$verhoudingen_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(verhoudingen$verhoudingen_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(verhoudingen$verhoudingen_obli)[parameterEstimates(verhoudingen$verhoudingen_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(verhoudingen$verhoudingen_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: verhoudingen - Model-fit statistieken**

```{r verhoudingen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de andere model-fit indices goed. Zowel de RMSE, TLI, en CRMS zijn goed of acceptabel.
Gezien de nummer van observaties (N =`r lavInspect(verhoudingen$verhoudingen_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: verhoudingen - Model-fit statistieken**

```{r verhoudingen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_rekenen_VH_C_1F_011      :  0.2869485
- ASL7_rekenen_VH_C_2F_037      :  0.2764919
- ASL7_rekenen_VH_C_2F_036_pilot: -0.0140967
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings verhoudingen**
```{r verhoudingen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings verhoudingen", sub = "Item factor loadings; order based on item factor loadings order")
```


### "verschillen"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de verschillen, waarbij de factor analyse en de principiele verschillen analyse zijn weergegeven.
Beide verschillen zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot verschillen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/verschillen_scree_plot.png)

**Figuur 33: Parallel plot verschillen**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/verschillen_parallel_plot.png)


#### Statitische Methoden

```{r verschillen - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(verschillen$verschillen_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(verschillen$verschillen_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(verschillen$verschillen_obli)[parameterEstimates(verschillen$verschillen_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(verschillen$verschillen_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: verschillen - Model-fit statistieken**

```{r verschillen - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn relatief positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), RMSEA en CRMS zijn goed en acceptabel, respctievelijk. 
Gezien de nummer van observaties (N =`r lavInspect(verschillen$verschillen_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: verschillen - Model-fit statistieken**

```{r verschillen - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_verschillen_001: 0.2910539
- ASL_verschillen_012: 0.2823816
- ASL_verschillen_004: 0.2746317
- ASL_verschillen_017: 0.2293197
- ASL_verschillen_014: 0.2190430
- ASL_verschillen_021: 0.2180344
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings verschillen**
```{r verschillen - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings verschillen", sub = "Item factor loadings; order based on item factor loadings order")
```

Mochten de bovengenoemde vragen te veel zijn om te heroverwegen, dan wordt geadviseerd om op zijn minst de volgende vragen te heroverwegen:

- ASL_verschillen_017: 0.2293197
- ASL_verschillen_014: 0.06079612
- ASL_verschillen_021: 0.03880664


### "werkwoordspelling"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de werkwoordspelling, waarbij de factor analyse en de principiele werkwoordspelling analyse zijn weergegeven.
Beide werkwoordspelling zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot werkwoordspelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/werkwoordspelling_scree_plot.png)

**Figuur 33: Parallel plot werkwoordspelling**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/werkwoordspelling_parallel_plot.png)


#### Statitische Methoden

```{r werkwoordspelling - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(werkwoordspelling$werkwoordspelling_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(werkwoordspelling$werkwoordspelling_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(werkwoordspelling$werkwoordspelling_obli)[parameterEstimates(werkwoordspelling$werkwoordspelling_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(werkwoordspelling$werkwoordspelling_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.

**Tabel 22: werkwoordspelling - Model-fit statistieken**

```{r werkwoordspelling - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Acceptable", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices zijn relatief positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), zijn de RMSEA en CRMS goed en acceptabel, respctievelijk.
Gezien de nummer van observaties (N =`r lavInspect(werkwoordspelling$werkwoordspelling_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model te overwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: werkwoordspelling - Model-fit statistieken**

```{r werkwoordspelling - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL7_taalverzorging_WS_2F_023      :  0.2944952
- ASL7_taalverzorging_WS_3F_026      :  0.2898023
- ASL7_taalverzorging_WS_1F_003      :  0.2865123
- ASL7_taalverzorging_WS_2F_015      :  0.2640686
- ASL7_taalverzorging_WS_2F_014      :  0.2566777
- ASL7_taalverzorging_WS_3F_025      :  0.1696574
- ASL7_taalverzorging_WS_1F_009_pilot: -0.0402707
   
Zie hieronder voor een grafische weergave:`

**Figuur 34: Factor Loadings werkwoordspelling**
```{r werkwoordspelling - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings werkwoordspelling", sub = "Item factor loadings; order based on item factor loadings order")
```

Op basis van de resultaten, wordt in eerste instantie geadviseerd te kijken naar een 2-factor model.
Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om op zijn minst de volgende vragen te herevalueren:
- ASL7_taalverzorging_WS_3F_025      :  0.17066334
- ASL7_taalverzorging_WS_1F_009_pilot: -0.04235494

En eventueel:

- ASL7_taalverzorging_WS_2F_015      :  0.26737405
- ASL7_taalverzorging_WS_2F_014      :  0.26040021

De restant van de vragen zitten heel dicht bij de .3 grenz, en kunnen genegeerd worden.


### "woorden"

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de woorden, waarbij de factor analyse en de principiele woorden analyse zijn weergegeven.
Beide woorden zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot woorden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/woorden_scree_plot.png)

**Figuur 33: Parallel plot woorden**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/woorden_parallel_plot.png)


#### Statitische Methoden

```{r woorden - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(woorden$woorden_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(woorden$woorden_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(woorden$woorden_obli)[parameterEstimates(woorden$woorden_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(woorden$woorden_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woorden - Model-fit statistieken**

```{r woorden - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Poor", "Good", "Poor")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed. 
Gezien de nummer van observaties (N =`r lavInspect(woorden$woorden_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woorden - Model-fit statistieken**

```{r woorden - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)


colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_woorden_015: 0.2884748
- ASL_woorden_008: 0.2806403
- ASL_woorden_003: 0.2788584
- ASL_woorden_006: 0.2772143
- ASL_woorden_002: 0.2583989
- ASL_woorden_001: 0.2506008
- ASL_woorden_012: 0.2418926
- ASL_woorden_019: 0.1508892
- ASL_woorden_009: 0.1469615
- ASL_woorden_014: 0.1407500

   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings woorden**
```{r woorden - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings woorden", sub = "Item factor loadings; order based on item factor loadings order")
```
Op basis van de resultaten, wordt in eerste instantie geadviseerd te kijken naar een 2-factor model.
Mocht het 1-factor model dwingend zijn, dan wordt geadviseerd om op zijn minst de volgende vragen te herevalueren:

- ASL_woorden_009: 0.1490782
- ASL_woorden_019: 0.1488297
- ASL_woorden_014: 0.1394278


### Woorden Relateren

Hieronder, in figuur 23 en 24, zie je de resultaten van de grafische methoden voor de woordenrelateren, waarbij de factor analyse en de principiele woordenrelateren analyse zijn weergegeven.
Beide woordenrelateren zijn soortgelijk te interpreteren; in de plots staan de eigen values weergegeven op de verticale axis, en het aantal factoren op de horizontale axis. In Beide
grafieken wordt een cut-off weergegeven in de vorm van of een vaste zwarte lijn (Eigenvalues > 1), of een rode stippellijn (simulatie vergelijk). De hoeveelheid factoren
die boven deze lijn uitkomen, zijn de aanbevolen hoeveelheid factoren voor de betreffende onderdeel. 

**Figuur 32: Screeplot woordenrelateren**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/woordenrelateren_scree_plot.png)

**Figuur 33: Parallel plot woordenrelateren**

![](/Users/jesse/Repos/r-jvb-aansluiting/data/factor_analyses_simple`r format(Sys.Date(), "%Y")`/fa_graphs/woordenrelateren_parallel_plot.png)


#### Statitische Methoden

```{r woordenrelateren - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(woordenrelateren$woordenrelateren_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea.robust"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue.robust"][[1]] # > .05
tli <- fit["tli.robust"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi.robust"][[1]] # > 0.90


# Explained variance
r2 <- inspect(woordenrelateren$woordenrelateren_obli, what = "r2")

# Factor loadings
loadings <- parameterEstimates(woordenrelateren$woordenrelateren_obli)[parameterEstimates(woordenrelateren$woordenrelateren_obli)$op == "=~", ][c("rhs", "est")]
weights <- inspect(woordenrelateren$woordenrelateren_obli, what = "std")[["lambda"]] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r woordenrelateren - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(woordenrelateren$woordenrelateren_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r woordenrelateren - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings$rhs,
  factor_loadings = weights[match(loadings$rhs, rownames(weights)), "f1"],
  weights = loadings$est,
  r2 = r2
)

colnames(df)[colnames(df) == "f1"] <- "factor_loadings"


df <- df[order(df$factor_loadings, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading", "unstd. Factor Loading", "Explained Variance"))
```

Op basis van de factor loadings zijn er enkele vraag die heroverwogen kunnen worden:

- ASL_woordenrelateren_017: 0.2845585
- ASL_woordenrelateren_004: 0.2642922
- ASL_woordenrelateren_006: 0.2493562
- ASL_woordenrelateren_016: 0.1954447
   
Zie hieronder voor een grafische weergave:

**Figuur 34: Factor Loadings woordenrelateren**
```{r woordenrelateren - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
plot <- plot(df$factor_loadings)
plot <- lines(df$factor_loadings)
plot <- abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
plot <- title(main = "Factor Loadings woordenrelateren", sub = "Item factor loadings; order based on item factor loadings order")
```
Mocht het noodzakelijk zijn slechts een vraag te heroverwegen, dan wordt geadviseerd om de volgende vraag te herevalueren:

- ASL_woordenrelateren_016:0.1954447


## Alternatieve Resultaten

```{r alternative results, echo=FALSE, message=FALSE, warning=FALSE}
names <- list.files(here(paste0("data/factor_analyses", format(Sys.Date(), "%Y"), "/alternative_factors")), full.names = TRUE)
names <- names[grepl(".Rdata", names)]


# Load files
for (file in names) {
  load(file, envir = .GlobalEnv)
  # Rename an object in the global environment
  assign(file_path_sans_ext(basename(file)), factor_analyses, envir = .GlobalEnv)
  rm(file)
}
rm(names)
```

Hieronder volgen de alternatieve modellen en diens resultaten. De gekozen nummer factoren komen uit tabel 1.

### Cijfers 2

```{r cijfers 2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(cijfers_2$cijfers_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue"][[1]] # > .05
tli <- fit["tli"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi"][[1]] # > 0.90


# Explained variance
r2 <- inspect(cijfers_2$cijfers_obli, what = "r2")

# Factor loadings
loadings_1 <- parameterEstimates(cijfers_2$cijfers_obli)[parameterEstimates(cijfers_2$cijfers_obli)$op == "=~" & parameterEstimates(cijfers_2$cijfers_obli)$lhs == "f1", ][c("rhs", "est")]
loadings_2 <- parameterEstimates(cijfers_2$cijfers_obli)[parameterEstimates(cijfers_2$cijfers_obli)$op == "=~" & parameterEstimates(cijfers_2$cijfers_obli)$lhs == "f2", ][c("rhs", "est")]
weights_1 <- inspect(cijfers_2$cijfers_obli, what = "std")[["lambda"]][, "f1"] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
weights_2 <- inspect(cijfers_2$cijfers_obli, what = "std")[["lambda"]][, "f2"]
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r cijfers 2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(cijfers_2$cijfers_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r cijfers 2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings_1$rhs,
  factor_loadings_1 = as.numeric(weights_1),
  factor_loadings_2 = as.numeric(weights_2),
  weights_1 = loadings_1$est,
  weights_2 = loadings_2$est,
  r2 = r2
)
weights_1
weights_2
df <- df[order(df$factor_loadings_1, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading 1", "std. Factor Loading 2", "unstd. Factor Loading 1", "unstd. Factor Loading 2", "Explained Variance"))
```

Gebaseerd op het 2-factor model, blijken er nog 2 vragen over te blijven die niet goed laden:

- ASL_cijfers_020: 0.05640137, 0.1932376
- ASL_cijfers_019: 0.01708625, 0.2826749

In de volgende grafiek zijn de factor loadings weergegeven, op volgorde van factor_loading_1.

```{r cijfers 2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$naam)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings_1, col = "red", type = "o")
lines(x, df$factor_loadings_2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
df[df$factor_loadings_1 < 0.3 & df$factor_loadings_2 < 0.3, ]
```


### Lezen_deel1 2

```{r lezen_deel1 2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(lezen_deel1_2$lezen_deel1_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue"][[1]] # > .05
tli <- fit["tli"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi"][[1]] # > 0.90


# Explained variance
r2 <- inspect(lezen_deel1_2$lezen_deel1_obli, what = "r2")

# Factor loadings
loadings_1 <- parameterEstimates(lezen_deel1_2$lezen_deel1_obli)[parameterEstimates(lezen_deel1_2$lezen_deel1_obli)$op == "=~" & parameterEstimates(lezen_deel1_2$lezen_deel1_obli)$lhs == "f1", ][c("rhs", "est")]
loadings_2 <- parameterEstimates(lezen_deel1_2$lezen_deel1_obli)[parameterEstimates(lezen_deel1_2$lezen_deel1_obli)$op == "=~" & parameterEstimates(lezen_deel1_2$lezen_deel1_obli)$lhs == "f2", ][c("rhs", "est")]
weights_1 <- inspect(lezen_deel1_2$lezen_deel1_obli, what = "std")[["lambda"]][, "f1"] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
weights_2 <- inspect(lezen_deel1_2$lezen_deel1_obli, what = "std")[["lambda"]][, "f2"]
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r lezen_deel1 2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(lezen_deel1_2$lezen_deel1_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r lezen_deel1 2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings_1$rhs,
  factor_loadings_1 = as.numeric(weights_1),
  factor_loadings_2 = as.numeric(weights_2),
  weights_1 = loadings_1$est,
  weights_2 = loadings_2$est,
  r2 = r2
)

df <- df[order(df$factor_loadings_1, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading 1", "std. Factor Loading 2", "unstd. Factor Loading 1", "unstd. Factor Loading 2", "Explained Variance"))
```

Gebaseerd op het 2-factor model, blijken er meerdere vragen

-      ASL_lezen_LV_bomen_2F_007: 0.288097626, 0.27603942
- ASL7_lezen_LV_SUPERSOEP_1F_004: 0.268918792, 0.10860546
-      ASL_lezen_LV_bomen_2F_004: 0.227734352, 0.26967497
-      ASL_lezen_LV_bomen_2F_010: 0.224248910, 0.23784614
- ASL7_lezen_LV_SUPERSOEP_1F_006: 0.210549946, 0.08656182
-      ASL_lezen_LV_bomen_2F_009: 0.205094179, 0.22474929
- ASL7_lezen_LV_SUPERSOEP_1F_001: 0.112679191, 0.07143976
-   ASL7_lezen_LV_OCHTEND_2F_009: 0.009208496, 0.28548153

In de volgende grafiek zijn de factor loadings weergegeven, op volgorde van factor_loading_1.

```{r lezen_deel1 2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$naam)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings_1, col = "red", type = "o")
lines(x, df$factor_loadings_2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
df[df$factor_loadings_1 < 0.3 & df$factor_loadings_2 < 0.3, ]
```


### Lezen_deel2 2

```{r lezen_deel2 2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(lezen_deel2_2$lezen_deel2_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue"][[1]] # > .05
tli <- fit["tli"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi"][[1]] # > 0.90


# Explained variance
r2 <- inspect(lezen_deel2_2$lezen_deel2_obli, what = "r2")

# Factor loadings
loadings_1 <- parameterEstimates(lezen_deel2_2$lezen_deel2_obli)[parameterEstimates(lezen_deel2_2$lezen_deel2_obli)$op == "=~" & parameterEstimates(lezen_deel2_2$lezen_deel2_obli)$lhs == "f1", ][c("rhs", "est")]
loadings_2 <- parameterEstimates(lezen_deel2_2$lezen_deel2_obli)[parameterEstimates(lezen_deel2_2$lezen_deel2_obli)$op == "=~" & parameterEstimates(lezen_deel2_2$lezen_deel2_obli)$lhs == "f2", ][c("rhs", "est")]
weights_1 <- inspect(lezen_deel2_2$lezen_deel2_obli, what = "std")[["lambda"]][, "f1"] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
weights_2 <- inspect(lezen_deel2_2$lezen_deel2_obli, what = "std")[["lambda"]][, "f2"]
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r lezen_deel2 2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(lezen_deel2_2$lezen_deel2_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r lezen_deel2 2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings_1$rhs,
  factor_loadings_1 = as.numeric(weights_1),
  factor_loadings_2 = as.numeric(weights_2),
  weights_1 = loadings_1$est,
  weights_2 = loadings_2$est,
  r2 = r2
)

df <- df[order(df$factor_loadings_1, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading 1", "std. Factor Loading 2", "unstd. Factor Loading 1", "unstd. Factor Loading 2", "Explained Variance"))
```

Gebaseerd op het 2-factor model, blijken er meerdere vragen

-   ASL7_lezen_LV_SIBERI_1F_001: 0.24040474, 0.1524084
- ASL7_lezen_LV_FIETSHELM_0F_005: 0.21076463, 0.1765066
-   ASL7_lezen_LV_SIBERI_1F_005: 0.17716798, 0.1878367
-   ASL7_lezen_LV_SIBERI_1F_008: 0.11677837, 0.1618846
-      ASL7_lezen_LV_REIS_2F_004: 0.05534024, 0.2707231

In de volgende grafiek zijn de factor loadings weergegeven, op volgorde van factor_loading_1.

```{r lezen_deel2 2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$naam)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings_1, col = "red", type = "o")
lines(x, df$factor_loadings_2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
df[df$factor_loadings_1 < 0.3 & df$factor_loadings_2 < 0.3, ]
```

### Sommenmaken 2

```{r sommenmaken 2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(sommenmaken_2$sommenmaken_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue"][[1]] # > .05
tli <- fit["tli"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi"][[1]] # > 0.90


# Explained variance
r2 <- inspect(sommenmaken_2$sommenmaken_obli, what = "r2")

# Factor loadings
loadings_1 <- parameterEstimates(sommenmaken_2$sommenmaken_obli)[parameterEstimates(sommenmaken_2$sommenmaken_obli)$op == "=~" & parameterEstimates(sommenmaken_2$sommenmaken_obli)$lhs == "f1", ][c("rhs", "est")]
loadings_2 <- parameterEstimates(sommenmaken_2$sommenmaken_obli)[parameterEstimates(sommenmaken_2$sommenmaken_obli)$op == "=~" & parameterEstimates(sommenmaken_2$sommenmaken_obli)$lhs == "f2", ][c("rhs", "est")]
weights_1 <- inspect(sommenmaken_2$sommenmaken_obli, what = "std")[["lambda"]][, "f1"] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
weights_2 <- inspect(sommenmaken_2$sommenmaken_obli, what = "std")[["lambda"]][, "f2"]
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r sommenmaken 2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(sommenmaken_2$sommenmaken_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r sommenmaken 2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings_1$rhs,
  factor_loadings_1 = as.numeric(weights_1),
  factor_loadings_2 = as.numeric(weights_2),
  weights_1 = loadings_1$est,
  weights_2 = loadings_2$est,
  r2 = r2
)

df <- df[order(df$factor_loadings_1, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading 1", "std. Factor Loading 2", "unstd. Factor Loading 1", "unstd. Factor Loading 2", "Explained Variance"))
```

Gebaseerd op het 2-factor model, zijn er geen vragen die heroverwogen hoeven te worden.

In de volgende grafiek zijn de factor loadings weergegeven, op volgorde van factor_loading_1.

```{r sommenmaken 2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$naam)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings_1, col = "red", type = "o")
lines(x, df$factor_loadings_2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
df[df$factor_loadings_1 < 0.3 & df$factor_loadings_2 < 0.3, ]
```


### Spelling 3

```{r spelling 3 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(spelling_3$spelling_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]

# model fit indices
rmsea <- fit["rmsea"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue"][[1]] # > .05
tli <- fit["tli"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi"][[1]] # > 0.90


# Explained variance
r2 <- inspect(spelling_3$spelling_obli, what = "r2")

# Factor loadings
loadings_1 <- parameterEstimates(spelling_3$spelling_obli)[parameterEstimates(spelling_3$spelling_obli)$op == "=~" & parameterEstimates(spelling_3$spelling_obli)$lhs == "f1", ][c("rhs", "est")]
loadings_2 <- parameterEstimates(spelling_3$spelling_obli)[parameterEstimates(spelling_3$spelling_obli)$op == "=~" & parameterEstimates(spelling_3$spelling_obli)$lhs == "f2", ][c("rhs", "est")]
loadings_3 <- parameterEstimates(spelling_3$spelling_obli)[parameterEstimates(spelling_3$spelling_obli)$op == "=~" & parameterEstimates(spelling_3$spelling_obli)$lhs == "f3", ][c("rhs", "est")]
weights_1 <- inspect(spelling_3$spelling_obli, what = "std")[["lambda"]][, "f1"] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
weights_2 <- inspect(spelling_3$spelling_obli, what = "std")[["lambda"]][, "f2"]
weights_3 <- inspect(spelling_3$spelling_obli, what = "std")[["lambda"]][, "f3"]
```
##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r spelling 3 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Acceptable")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(spelling_3$spelling_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r spelling 3 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings_1$rhs,
  factor_loadings_1 = as.numeric(weights_1),
  factor_loadings_2 = as.numeric(weights_2),
  factor_loadings_3 = as.numeric(weights_3),
  weights_1 = loadings_1$est,
  weights_2 = loadings_2$est,
  weights_3 = loadings_3$est,
  r2 = r2
)

df <- df[order(df$factor_loadings_1, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading 1", "std. Factor Loading 2", "std. Factor Loading 3", "unstd. Factor Loading 1", "unstd. Factor Loading 2", "unstd. Factor Loading 3", "Explained Variance"))
```

Gebaseerd op het 2-factor model, blijken er meerdere vragen

-      ASL7_taalverzorging_SP_2F_024:  0.29096380,  0.05224613, 0.25891061
-      ASL7_taalverzorging_SP_2F_027:  0.28043814,  0.21004481, 0.14993227
-    ET2020_taalverzorging_SP_3F_107:  0.26007388,  0.22791075, 0.29213843
-      ASL7_taalverzorging_SP_2F_029:  0.24554511,  0.11302183, 0.14831713
-      ASL7_taalverzorging_SP_1F_015:  0.22608028,  0.05069734, 0.25831813
-      ASL7_taalverzorging_SP_3F_037:  0.21966619,  0.03412746, 0.27243416
-    ET2020_taalverzorging_SP_2F_169:  0.21090400,  0.12396137, 0.26390440
-    ET2020_taalverzorging_SP_3F_129:  0.20874622,  0.14767496, 0.26802724
- ASL_taalverzorging_SP_3F_019_anker:  0.19046587,  0.02130589, 0.27014451
-      ASL7_taalverzorging_SP_2F_028:  0.18759912,  0.01513262, 0.20657276
-    ET2020_taalverzorging_SP_3F_118:  0.15476778,  0.16998234, 0.16719373
-    ET2020_taalverzorging_SP_1F_179:  0.14976955,  0.07969654, 0.22655592
-    ET2020_taalverzorging_SP_3F_139:  0.14836621,  0.07481830, 0.21114366
-    ET2020_taalverzorging_SP_1F_143:  0.14071068,  0.05276360, 0.23897619
-      ASL7_taalverzorging_SP_2F_031:  0.11080785,  0.03621342, 0.15585166
-    ET2020_taalverzorging_SP_1F_178:  0.10426786,  0.09945534, 0.18450459
-    ET2020_taalverzorging_SP_3F_182:  0.07723290,  0.05590278, 0.15416832
-    ET2020_taalverzorging_SP_3F_150: -0.02717044, -0.05379780, 0.02804564

In de volgende grafiek zijn de factor loadings weergegeven, op volgorde van factor_loading_1.

```{r spelling 3 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$naam)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings_1, col = "red", type = "o")
lines(x, df$factor_loadings_2, col = "blue", type = "o")
lines(x, df$factor_loadings_3, col = "green", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2", "Factor 3"), col = c("red", "blue", "green"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
df[df$factor_loadings_1 < 0.3 & df$factor_loadings_2 < 0.3 & df$factor_loadings_3 < 0.3, ]
```

### Werkwoordspelling 2

```{r werkwoordspelling 2 - stat extraction, echo=FALSE, message=FALSE, warning=FALSE}
fit <- fitMeasures(werkwoordspelling_2$werkwoordspelling_obli)
# null hypothesis: empirical chi-square
p <- round(fit["pvalue"][[1]], 3)
chisq <- fit["chisq"][[1]]
summary(werkwoordspelling_2$werkwoordspelling_obli)
# model fit indices
rmsea <- fit["rmsea"][[1]] # < .06 or .08
p_rmsea <- fit["rmsea.pvalue"][[1]] # > .05
tli <- fit["tli"][[1]] # > 0.95
rms <- fit["crmr"][[1]] # correct RMS, < 0.08
cfi <- fit["cfi"][[1]] # > 0.90


# Explained variance
r2 <- inspect(werkwoordspelling_2$werkwoordspelling_obli, what = "r2")

# Factor loadings
loadings_1 <- parameterEstimates(werkwoordspelling_2$werkwoordspelling_obli)[parameterEstimates(werkwoordspelling_2$werkwoordspelling_obli)$op == "=~" & parameterEstimates(werkwoordspelling_2$werkwoordspelling_obli)$lhs == "f1", ][c("rhs", "est")]
loadings_2 <- parameterEstimates(werkwoordspelling_2$werkwoordspelling_obli)[parameterEstimates(werkwoordspelling_2$werkwoordspelling_obli)$op == "=~" & parameterEstimates(werkwoordspelling_2$werkwoordspelling_obli)$lhs == "f2", ][c("rhs", "est")]
weights_1 <- inspect(werkwoordspelling_2$werkwoordspelling_obli, what = "std")[["lambda"]][, "f1"] # These are the factor score coefficients, which are used to compute factor scores for each observation in your data.
weights_2 <- inspect(werkwoordspelling_2$werkwoordspelling_obli, what = "std")[["lambda"]][, "f2"]
```

##### Model Beoordeling

Hieronder, in tabel 2, zie je de model-fit statistieken van de CFA voor betekenissen. Hierbij een korte uitleg wat het exact betekent:

- p-value: de p-waarde van de empirische chi-square. Als deze kleiner is dan .05, dan is er een significant verschil tussen de empirische en de geschatte chi-square. Dit betekent dat het model niet goed past.
- RMSEA: RMSEA meet hoe goed een model de waargenomen data benadert, rekening houdend met de fout in het model. Lagere waarden duiden op een betere pasvorm, typisch onder 0.05 voor goede pasvorm en tussen 0.05 en 0.08 voor redelijke pasvorm.
- TLI: de Tucker-Lewis Index. TLI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.
- CRMS: de Corrected Root Mean Square. Dit kwantificeert het gemiddelde verschil tussen waargenomen en voorspelde waarden in een model. Het geeft een maat voor hoe goed de voorspellingen van het model overeenkomen met de daadwerkelijke gegevens. Lagere RMRS-waarden geven een betere overeenkomst aan, wat wijst op een nauwkeuriger model.
- CFI: de Comparative Fit Index. De CFI is een pasvormindex gebruikt in structurele vergelijkingsmodellen om de relatieve verbetering van het gespecificeerde model te beoordelen in vergelijking met een basismodel. Waarden dicht bij 1 geven een betere pasvorm aan, met een gemeenschappelijke grenswaarde voor acceptabele pasvorm van 0.90 of hoger.


**Tabel 22: woordenrelateren - Model-fit statistieken**

```{r werkwoordspelling 2 - model fit table, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  Statistic_Name = c("p-value", "RMSEA", "TLI", "CRMS", "CFI"),
  Result = c(p, rmsea, tli, rms, cfi),
  Cut_off = c("> .05", "< .05 | .05 - .1 | > .1", "> .95 | .90 - .95 | < .90", "< .08 | .08 - .10 | > .10", "> .95 | .90 - .95 | < .90"),
  Conclusion = c("Poor", "Good", "Acceptable", "Good", "Good")
)

# Create table
knitr::kable(df, col.names = c("Statistic", "Result", "Cut-off", "Conclusion"))
```

De model fit indices relatief zijn positief. Ondanks een significante p-waarde van de empirische chi-square test (chi-square = `r chisq`, p < `r p`), en de RMSEA en CRMS zijn goed, en de TLI acceptabel 
Gezien de nummer van observaties (N =`r lavInspect(werkwoordspelling_2$werkwoordspelling_obli, what = "nobs")`), is het verstandiger om de p-waarde van de empirische chi-square test als minder betrouwbaar te zien. Op basis hiervan,
als ook op basis van de recommended factors in figuur 1, wordt geadviseerd om het factor model niet te heroverwegen.

##### Item Beoordeling

Hieronder staan de factor loadings, factor weights, communalities, en uniquenesses weergegeven. Hieronder een beknopte uitleg van wat deze waarden betekenen:

- Factor loadings: de factor loadings geven aan hoe sterk een item correleert met een factor. Hoe hoger de factor loading, hoe sterker de correlatie. Een factor loading van .3 of hoger wordt gezien als een goede factor loading.
- Factor weights: de factor weights geven aan hoeveel gewicht een item heeft op een factor. Deze wordt gebruikt om de factor scores te berekenen. Hoe hoger de factor weight, hoe meer gewicht een item heeft op een factor.


**Tabel 23: woordenrelateren - Model-fit statistieken**

```{r werkwoordspelling 2 - Item loadings, echo=FALSE, message=FALSE, warning=FALSE}
# Create dataframe
df <- data.frame(
  naam = loadings_1$rhs,
  factor_loadings_1 = as.numeric(weights_1),
  factor_loadings_2 = as.numeric(weights_2),
  weights_1 = loadings_1$est,
  weights_2 = loadings_2$est,
  r2 = r2
)

df <- df[order(df$factor_loadings_1, decreasing = TRUE), ]
rownames(df) <- NULL

# Create table
knitr::kable(df, col.names = c("Naam", "std. Factor Loading 1", "std. Factor Loading 2", "unstd. Factor Loading 1", "unstd. Factor Loading 2", "Explained Variance"))
```

Het lijkt erop dat het 2-factor model niet laad. De fit indices zijn slecht, en de waardes voor beide factroren zijn hetzelfde. 

```{r werkworodspelling 2 - factor loadings plot, echo=FALSE, message=FALSE, warning=FALSE}
# Create a sequence of indices for the x-axis
x <- seq_along(df$naam)

# Create the initial scatter plot with dots for the first set of data
plot(x, df$factor_loadings_1, col = "red", type = "o")
lines(x, df$factor_loadings_2, col = "blue", type = "o")
abline(h = 0.3, lty = 2) # lty = 2 makes the line dashed
legend("topright", legend = c("Factor 1", "Factor 2"), col = c("red", "blue"), pch = 21, lty = 1)
title(main = "Factor Loadings spelling", sub = "Item factor loadings; order based on item factor loadings order")
df[df$factor_loadings_1 < 0.3 & df$factor_loadings_2 < 0.3, ]
```